{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.802-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lOJyGNulRuLz"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0hvCHj-ENz0",
        "colab_type": "text"
      },
      "source": [
        "## Comparison of CNN Models for Mass Detection in Mammography Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nk0snQ9Hctk",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOJk0KVCHLZd",
        "colab_type": "text"
      },
      "source": [
        "First we install any necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybsBL2-yBsE6",
        "colab_type": "code",
        "outputId": "3c004f0c-dd1d-420f-ca0e-a2b91fe77135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!pip install pydicom\n",
        "!pip install livelossplot\n",
        "\n",
        "print('Installed packages.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (1.4.2)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (46.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib; python_version >= \"3.6\"->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.1.9)\n",
            "Installed packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuzvIH8MHWwF",
        "colab_type": "text"
      },
      "source": [
        "Then we load the packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAXGa4ytGd-v",
        "colab_type": "code",
        "outputId": "96d76bc0-7071-4e24-e1f9-293efe156331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "import pydicom\n",
        "import cv2\n",
        "import plistlib\n",
        "import random\n",
        "import livelossplot\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras as K\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn import preprocessing\n",
        "from skimage import transform\n",
        "from sklearn.feature_extraction import image\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.draw import polygon\n",
        "from skimage.util import view_as_blocks\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.patches import Rectangle\n",
        "from keras.applications import vgg19, resnet_v2, nasnet, densenet, mobilenet_v2, inception_v3, xception\n",
        "\n",
        "print('Loaded packages.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlYiGDPnn4Oe",
        "colab_type": "text"
      },
      "source": [
        "Here's some shared code for the pre-processing and train/evaluation steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PShAhx47n4ZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "597b6661-6a8f-4542-bb2e-400c895362e7"
      },
      "source": [
        "patch_size = (224,224)\n",
        "input_shape = patch_size + (3,)\n",
        "\n",
        "print('Defined input shape.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined input shape.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr_vUD4k13mS",
        "colab_type": "code",
        "outputId": "b326c755-fb9a-4158-f08b-3eb2c4712a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def make_conv_base(model):\n",
        "  return model(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "print('Loaded convolutional bases.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded convolutional bases.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOoQoogsW_wu",
        "colab_type": "code",
        "outputId": "91f3595a-4e84-47d4-e4b7-40a760411cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class TimeHistory(K.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "plot_losses = livelossplot.PlotLossesKeras()\n",
        "es = K.callbacks.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "checkpointer = K.callbacks.callbacks.ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)\n",
        "scoring_encoding = {\n",
        "    '1': 1,\n",
        "    '2': 2,\n",
        "    '3': 3,\n",
        "    '4a': 4,\n",
        "    '4b': 5,\n",
        "    '4c': 6,\n",
        "    '5': 7,\n",
        "    '6': 8\n",
        "}\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "  beginning_time = time.time()\n",
        "  y_pred = model.predict(x_test)\n",
        "  ending_time = time.time()\n",
        "  evaluation = model.evaluate(x_test, y_test)\n",
        "  return y_pred, evaluation, ending_time-beginning_time\n",
        "\n",
        "print('Defined training utilities.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined training utilities.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGZIwd1XRXw-",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing\n",
        "Patch extraction and zero mean normalization. We write to a Google Drive to store the data and labels, so this section doesn't need to be run unless you need to perform pre-processing again. If you're satisfied with the Google Drive contents, you can proceed to the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUKfMee_EY10",
        "colab_type": "text"
      },
      "source": [
        "We load the [INBreast](https://github.com/wentaozhu/deep-mil-for-whole-mammogram-classification/issues/12) dataset from Dropbox."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGiGWEQ2GTSw",
        "colab_type": "code",
        "outputId": "868fc981-fa4d-49b9-8036-a78da1bc243f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget -O inbreast https://www.dropbox.com/sh/k0e06yayf50kspe/AADmoROCuzfffA6EhRKSqghGa?dl=0 inbreast\n",
        "!unzip inbreast -d /inbreast\n",
        "\n",
        "print('Loaded INBreast.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-05 17:47:26--  https://www.dropbox.com/sh/k0e06yayf50kspe/AADmoROCuzfffA6EhRKSqghGa?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/k0e06yayf50kspe/AADmoROCuzfffA6EhRKSqghGa [following]\n",
            "--2020-05-05 17:47:27--  https://www.dropbox.com/sh/raw/k0e06yayf50kspe/AADmoROCuzfffA6EhRKSqghGa\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb04843a193e802d981e07cc38e.dl.dropboxusercontent.com/zip_download_get/Aajz7jJGlN_NwpFsJGiPveZrl5T1svC7AjEkKbYU1ZiI2yPunOj35EVQGvpRQVZAOmNc8pre3UEYZd3E493Z4lNLKa7-FDRVUwwC_l5zv1y4fQ [following]\n",
            "--2020-05-05 17:47:34--  https://ucb04843a193e802d981e07cc38e.dl.dropboxusercontent.com/zip_download_get/Aajz7jJGlN_NwpFsJGiPveZrl5T1svC7AjEkKbYU1ZiI2yPunOj35EVQGvpRQVZAOmNc8pre3UEYZd3E493Z4lNLKa7-FDRVUwwC_l5zv1y4fQ\n",
            "Resolving ucb04843a193e802d981e07cc38e.dl.dropboxusercontent.com (ucb04843a193e802d981e07cc38e.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to ucb04843a193e802d981e07cc38e.dl.dropboxusercontent.com (ucb04843a193e802d981e07cc38e.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8696242182 (8.1G) [application/zip]\n",
            "Saving to: ‘inbreast’\n",
            "\n",
            "inbreast            100%[===================>]   8.10G  36.0MB/s    in 3m 42s  \n",
            "\n",
            "2020-05-05 17:51:16 (37.4 MB/s) - ‘inbreast’ saved [8696242182/8696242182]\n",
            "\n",
            "--2020-05-05 17:51:16--  http://inbreast/\n",
            "Resolving inbreast (inbreast)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘inbreast’\n",
            "FINISHED --2020-05-05 17:51:16--\n",
            "Total wall clock time: 3m 50s\n",
            "Downloaded: 1 files, 8.1G in 3m 42s (37.4 MB/s)\n",
            "Archive:  inbreast\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            "   creating: /inbreast/roi/\n",
            "   creating: /inbreast/xml/\n",
            "   creating: /inbreast/dicom/\n",
            "replace /inbreast/INbreast.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: /inbreast/INbreast.csv  \n",
            " extracting: /inbreast/xml/22614353.xml  \n",
            " extracting: /inbreast/xml/50996110.xml  \n",
            " extracting: /inbreast/roi/22613796.roi  \n",
            " extracting: /inbreast/roi/50995762.roi  \n",
            " extracting: /inbreast/xml/51049655.xml  \n",
            " extracting: /inbreast/roi/20587758.roi  \n",
            " extracting: /inbreast/xml/30011530.xml  \n",
            " extracting: /inbreast/xml/50998258.xml  \n",
            " extracting: /inbreast/roi/50993895.roi  \n",
            " extracting: /inbreast/xml/22580548.xml  \n",
            " extracting: /inbreast/roi/22613624.roi  \n",
            " extracting: /inbreast/xml/20587320.xml  \n",
            " extracting: /inbreast/xml/20588680.xml  \n",
            " extracting: /inbreast/xml/51049107.xml  \n",
            " extracting: /inbreast/xml/50995990.xml  \n",
            " extracting: /inbreast/roi/24065707.roi  \n",
            " extracting: /inbreast/roi/24055877.roi  \n",
            " extracting: /inbreast/roi/53587663.roi  \n",
            " extracting: /inbreast/roi/50998981.roi  \n",
            " extracting: /inbreast/roi/51049107.roi  \n",
            " extracting: /inbreast/xml/22580393.xml  \n",
            " extracting: /inbreast/roi/24055274.roi  \n",
            " extracting: /inbreast/xml/50998440.xml  \n",
            " extracting: /inbreast/roi/50996201.roi  \n",
            " extracting: /inbreast/roi/30011647.roi  \n",
            " extracting: /inbreast/xml/53586960.xml  \n",
            " extracting: /inbreast/roi/22678953.roi  \n",
            " extracting: /inbreast/roi/22427751.roi  \n",
            " extracting: /inbreast/roi/50998258.roi  \n",
            " extracting: /inbreast/roi/22670978.roi  \n",
            " extracting: /inbreast/roi/50997434.roi  \n",
            " extracting: /inbreast/xml/22613970.xml  \n",
            " extracting: /inbreast/xml/53582476.xml  \n",
            " extracting: /inbreast/xml/22613822.xml  \n",
            " extracting: /inbreast/xml/50994408.xml  \n",
            " extracting: /inbreast/xml/50998580.xml  \n",
            " extracting: /inbreast/xml/50997461.xml  \n",
            " extracting: /inbreast/xml/24055464.xml  \n",
            " extracting: /inbreast/roi/22678856.roi  \n",
            " extracting: /inbreast/xml/22614499.xml  \n",
            " extracting: /inbreast/xml/51049462.xml  \n",
            " extracting: /inbreast/roi/22670177.roi  \n",
            " extracting: /inbreast/roi/50998580.roi  \n",
            " extracting: /inbreast/roi/22678833.roi  \n",
            " extracting: /inbreast/xml/24055382.xml  \n",
            " extracting: /inbreast/xml/50999008.xml  \n",
            " extracting: /inbreast/roi/22613676.roi  \n",
            " extracting: /inbreast/xml/50996827.xml  \n",
            " extracting: /inbreast/roi/50993399.roi  \n",
            " extracting: /inbreast/roi/53580858.roi  \n",
            " extracting: /inbreast/roi/20588334.roi  \n",
            " extracting: /inbreast/roi/50998413.roi  \n",
            " extracting: /inbreast/xml/20588216.xml  \n",
            " extracting: /inbreast/xml/24065380.xml  \n",
            " extracting: /inbreast/xml/24055328.xml  \n",
            " extracting: /inbreast/roi/22580393.roi  \n",
            " extracting: /inbreast/roi/50993976.roi  \n",
            " extracting: /inbreast/roi/22613702.roi  \n",
            " extracting: /inbreast/roi/22614150.roi  \n",
            " extracting: /inbreast/xml/50999094.xml  \n",
            " extracting: /inbreast/xml/50994616.xml  \n",
            " extracting: /inbreast/roi/51049276.roi  \n",
            " extracting: /inbreast/xml/30011553.xml  \n",
            " extracting: /inbreast/roi/24055464.roi  \n",
            " extracting: /inbreast/xml/22678980.xml  \n",
            " extracting: /inbreast/roi/50996406.roi  \n",
            " extracting: /inbreast/xml/22614379.xml  \n",
            " extracting: /inbreast/xml/22614522.xml  \n",
            " extracting: /inbreast/xml/22670465.xml  \n",
            " extracting: /inbreast/roi/22670832.roi  \n",
            " extracting: /inbreast/roi/53586751.roi  \n",
            " extracting: /inbreast/roi/24055725.roi  \n",
            " extracting: /inbreast/roi/24055654.roi  \n",
            " extracting: /inbreast/roi/27829134.roi  \n",
            " extracting: /inbreast/roi/22580576.roi  \n",
            " extracting: /inbreast/xml/30011484.xml  \n",
            " extracting: /inbreast/roi/24055024.roi  \n",
            " extracting: /inbreast/roi/22670301.roi  \n",
            " extracting: /inbreast/xml/50998494.xml  \n",
            " extracting: /inbreast/roi/50996352.roi  \n",
            " extracting: /inbreast/roi/20587294.roi  \n",
            " extracting: /inbreast/xml/24055274.xml  \n",
            " extracting: /inbreast/xml/27829188.xml  \n",
            " extracting: /inbreast/xml/20588190.xml  \n",
            " extracting: /inbreast/roi/24065407.roi  \n",
            " extracting: /inbreast/xml/53586896.xml  \n",
            " extracting: /inbreast/roi/53580804.roi  \n",
            " extracting: /inbreast/roi/20587080.roi  \n",
            " extracting: /inbreast/xml/22579754.xml  \n",
            " extracting: /inbreast/xml/20588308.xml  \n",
            " extracting: /inbreast/roi/20587836.roi  \n",
            " extracting: /inbreast/roi/20586908.roi  \n",
            " extracting: /inbreast/roi/22614379.roi  \n",
            " extracting: /inbreast/xml/24058686.xml  \n",
            " extracting: /inbreast/xml/50998177.xml  \n",
            " extracting: /inbreast/roi/22670673.roi  \n",
            " extracting: /inbreast/xml/50994354.xml  \n",
            " extracting: /inbreast/xml/22580038.xml  \n",
            " extracting: /inbreast/xml/50996137.xml  \n",
            " extracting: /inbreast/xml/50997769.xml  \n",
            " extracting: /inbreast/roi/22427840.roi  \n",
            " extracting: /inbreast/xml/50993697.xml  \n",
            " extracting: /inbreast/xml/53582764.xml  \n",
            " extracting: /inbreast/xml/22614074.xml  \n",
            " extracting: /inbreast/xml/20587544.xml  \n",
            " extracting: /inbreast/xml/50993643.xml  \n",
            " extracting: /inbreast/roi/22670878.roi  \n",
            " extracting: /inbreast/roi/22613822.roi  \n",
            " extracting: /inbreast/roi/22614266.roi  \n",
            " extracting: /inbreast/xml/50996999.xml  \n",
            " extracting: /inbreast/roi/30011674.roi  \n",
            " extracting: /inbreast/xml/50993814.xml  \n",
            " extracting: /inbreast/roi/53587717.roi  \n",
            " extracting: /inbreast/roi/22670465.roi  \n",
            " extracting: /inbreast/xml/53587041.xml  \n",
            " extracting: /inbreast/roi/24055078.roi  \n",
            " extracting: /inbreast/xml/53582656.xml  \n",
            " extracting: /inbreast/xml/53587454.xml  \n",
            " extracting: /inbreast/roi/53586805.roi  \n",
            " extracting: /inbreast/xml/53587572.xml  \n",
            " extracting: /inbreast/roi/50997678.roi  \n",
            " extracting: /inbreast/xml/50998059.xml  \n",
            " extracting: /inbreast/xml/24065761.xml  \n",
            " extracting: /inbreast/roi/22679036.roi  \n",
            " extracting: /inbreast/xml/22670673.xml  \n",
            " extracting: /inbreast/roi/20588308.roi  \n",
            " extracting: /inbreast/xml/22670978.xml  \n",
            " extracting: /inbreast/xml/24058660.xml  \n",
            " extracting: /inbreast/roi/30011850.roi  \n",
            " extracting: /inbreast/roi/50999459.roi  \n",
            " extracting: /inbreast/xml/22427682.xml  \n",
            " extracting: /inbreast/xml/24055502.xml  \n",
            " extracting: /inbreast/roi/22670124.roi  \n",
            " extracting: /inbreast/roi/20587810.roi  \n",
            " extracting: /inbreast/xml/51070197.xml  \n",
            " extracting: /inbreast/roi/20587690.roi  \n",
            " extracting: /inbreast/roi/53582737.roi  \n",
            " extracting: /inbreast/roi/22670147.roi  \n",
            " extracting: /inbreast/xml/50997678.xml  \n",
            " extracting: /inbreast/xml/24065557.xml  \n",
            " extracting: /inbreast/roi/50997651.roi  \n",
            " extracting: /inbreast/roi/53581460.roi  \n",
            " extracting: /inbreast/xml/53587104.xml  \n",
            " extracting: /inbreast/xml/50996945.xml  \n",
            " extracting: /inbreast/xml/53586751.xml  \n",
            " extracting: /inbreast/roi/50993670.roi  \n",
            " extracting: /inbreast/roi/22613650.roi  \n",
            " extracting: /inbreast/roi/53587572.roi  \n",
            " extracting: /inbreast/xml/50998467.xml  \n",
            " extracting: /inbreast/roi/20588458.roi  \n",
            " extracting: /inbreast/xml/53582737.xml  \n",
            " extracting: /inbreast/xml/20587294.xml  \n",
            " extracting: /inbreast/xml/22670347.xml  \n",
            " extracting: /inbreast/roi/50998634.roi  \n",
            " extracting: /inbreast/roi/50997624.roi  \n",
            " extracting: /inbreast/roi/22678646.roi  \n",
            " extracting: /inbreast/xml/22614236.xml  \n",
            " extracting: /inbreast/xml/30011507.xml  \n",
            " extracting: /inbreast/roi/22670855.roi  \n",
            " extracting: /inbreast/roi/50996083.roi  \n",
            " extracting: /inbreast/roi/50993841.roi  \n",
            " extracting: /inbreast/xml/50995789.xml  \n",
            " extracting: /inbreast/xml/20587346.xml  \n",
            " extracting: /inbreast/xml/50996854.xml  \n",
            " extracting: /inbreast/xml/50999459.xml  \n",
            " extracting: /inbreast/roi/53587481.roi  \n",
            " extracting: /inbreast/xml/50994895.xml  \n",
            " extracting: /inbreast/xml/50996083.xml  \n",
            " extracting: /inbreast/roi/53587508.roi  \n",
            " extracting: /inbreast/roi/20588654.roi  \n",
            " extracting: /inbreast/roi/51049543.roi  \n",
            " extracting: /inbreast/roi/26933830.roi  \n",
            " extracting: /inbreast/xml/22678518.xml  \n",
            " extracting: /inbreast/roi/22427728.roi  \n",
            " extracting: /inbreast/xml/22678449.xml  \n",
            " extracting: /inbreast/roi/20588216.roi  \n",
            " extracting: /inbreast/roi/24055573.roi  \n",
            " extracting: /inbreast/roi/50997488.roi  \n",
            " extracting: /inbreast/roi/22580492.roi  \n",
            " extracting: /inbreast/roi/20587544.roi  \n",
            " extracting: /inbreast/roi/22614431.roi  \n",
            " extracting: /inbreast/xml/22580706.xml  \n",
            " extracting: /inbreast/roi/51049462.roi  \n",
            " extracting: /inbreast/roi/22580068.roi  \n",
            " extracting: /inbreast/xml/22580098.xml  \n",
            " extracting: /inbreast/xml/50998231.xml  \n",
            " extracting: /inbreast/xml/22427728.xml  \n",
            " extracting: /inbreast/xml/20588020.xml  \n",
            " extracting: /inbreast/roi/50997796.roi  \n",
            " extracting: /inbreast/roi/22580192.roi  \n",
            " extracting: /inbreast/roi/22678472.roi  \n",
            " extracting: /inbreast/xml/50997250.xml  \n",
            " extracting: /inbreast/roi/22579847.roi  \n",
            " extracting: /inbreast/roi/24055600.roi  \n",
            " extracting: /inbreast/xml/24055779.xml  \n",
            " extracting: /inbreast/roi/24055203.roi  \n",
            " extracting: /inbreast/roi/22614236.roi  \n",
            " extracting: /inbreast/roi/24055904.roi  \n",
            " extracting: /inbreast/roi/53581406.roi  \n",
            " extracting: /inbreast/xml/50994327.xml  \n",
            " extracting: /inbreast/roi/50996827.roi  \n",
            " extracting: /inbreast/roi/20586934.roi  \n",
            " extracting: /inbreast/xml/20587690.xml  \n",
            " extracting: /inbreast/xml/24065251.xml  \n",
            " extracting: /inbreast/roi/22580419.roi  \n",
            " extracting: /inbreast/xml/22670094.xml  \n",
            " extracting: /inbreast/xml/50997624.xml  \n",
            " extracting: /inbreast/roi/26933772.roi  \n",
            " extracting: /inbreast/xml/53587427.xml  \n",
            " extracting: /inbreast/roi/24065530.roi  \n",
            " extracting: /inbreast/roi/53587599.roi  \n",
            " extracting: /inbreast/roi/53582422.roi  \n",
            " extracting: /inbreast/roi/24055752.roi  \n",
            " extracting: /inbreast/roi/30011700.roi  \n",
            " extracting: /inbreast/xml/53581887.xml  \n",
            " extracting: /inbreast/xml/27829134.xml  \n",
            " extracting: /inbreast/xml/30011727.xml  \n",
            " extracting: /inbreast/roi/24065611.roi  \n",
            " extracting: /inbreast/xml/22678472.xml  \n",
            " extracting: /inbreast/xml/50997488.xml  \n",
            " extracting: /inbreast/roi/53580665.roi  \n",
            " extracting: /inbreast/xml/50994300.xml  \n",
            " extracting: /inbreast/roi/50996999.roi  \n",
            " extracting: /inbreast/xml/26933772.xml  \n",
            " extracting: /inbreast/xml/53580804.xml  \n",
            " extracting: /inbreast/xml/50996352.xml  \n",
            " extracting: /inbreast/xml/24055904.xml  \n",
            " extracting: /inbreast/roi/20587226.roi  \n",
            " extracting: /inbreast/roi/50998086.roi  \n",
            " extracting: /inbreast/roi/50994408.roi  \n",
            " extracting: /inbreast/xml/50993426.xml  \n",
            " extracting: /inbreast/roi/50996736.roi  \n",
            " extracting: /inbreast/xml/22427751.xml  \n",
            " extracting: /inbreast/xml/22670620.xml  \n",
            " extracting: /inbreast/xml/53581460.xml  \n",
            " extracting: /inbreast/xml/53581406.xml  \n",
            " extracting: /inbreast/xml/22580419.xml  \n",
            " extracting: /inbreast/roi/24055502.roi  \n",
            " extracting: /inbreast/xml/53587481.xml  \n",
            " extracting: /inbreast/xml/22670832.xml  \n",
            " extracting: /inbreast/xml/50996201.xml  \n",
            " extracting: /inbreast/roi/53586778.roi  \n",
            " extracting: /inbreast/xml/20588458.xml  \n",
            " extracting: /inbreast/xml/20587836.xml  \n",
            " extracting: /inbreast/xml/24055445.xml  \n",
            " extracting: /inbreast/roi/24055382.roi  \n",
            " extracting: /inbreast/roi/22580548.roi  \n",
            " extracting: /inbreast/roi/24065251.roi  \n",
            " extracting: /inbreast/xml/51048738.xml  \n",
            " extracting: /inbreast/roi/50999148.roi  \n",
            " extracting: /inbreast/xml/50993976.xml  \n",
            " extracting: /inbreast/xml/24055483.xml  \n",
            " extracting: /inbreast/roi/22427864.roi  \n",
            " extracting: /inbreast/xml/24055725.xml  \n",
            " extracting: /inbreast/roi/22427682.roi  \n",
            " extracting: /inbreast/roi/22613970.roi  \n",
            " extracting: /inbreast/xml/53582818.xml  \n",
            " extracting: /inbreast/roi/30011727.roi  \n",
            " extracting: /inbreast/roi/22614097.roi  \n",
            " extracting: /inbreast/xml/22580492.xml  \n",
            " extracting: /inbreast/xml/53587663.xml  \n",
            " extracting: /inbreast/xml/53582791.xml  \n",
            " extracting: /inbreast/roi/24055779.roi  \n",
            " extracting: /inbreast/xml/50993949.xml  \n",
            " extracting: /inbreast/roi/51049053.roi  \n",
            " extracting: /inbreast/roi/20587612.roi  \n",
            " extracting: /inbreast/xml/51049080.xml  \n",
            " extracting: /inbreast/roi/24055931.roi  \n",
            " extracting: /inbreast/xml/22670878.xml  \n",
            " extracting: /inbreast/roi/50999246.roi  \n",
            " extracting: /inbreast/roi/20587148.roi  \n",
            " extracting: /inbreast/xml/22670511.xml  \n",
            " extracting: /inbreast/roi/22580706.roi  \n",
            " extracting: /inbreast/roi/53580611.roi  \n",
            " extracting: /inbreast/roi/22678449.roi  \n",
            " extracting: /inbreast/xml/24055806.xml  \n",
            " extracting: /inbreast/roi/22670347.roi  \n",
            " extracting: /inbreast/roi/30011484.roi  \n",
            " extracting: /inbreast/xml/22614127.xml  \n",
            " extracting: /inbreast/roi/20588190.roi  \n",
            " extracting: /inbreast/roi/20587902.roi  \n",
            " extracting: /inbreast/xml/20588654.xml  \n",
            " extracting: /inbreast/xml/24065833.xml  \n",
            " extracting: /inbreast/roi/51048972.roi  \n",
            " extracting: /inbreast/roi/50994895.roi  \n",
            " extracting: /inbreast/roi/24055176.roi  \n",
            " extracting: /inbreast/xml/20587664.xml  \n",
            " extracting: /inbreast/roi/53580692.roi  \n",
            " extracting: /inbreast/xml/22579916.xml  \n",
            " extracting: /inbreast/xml/50997107.xml  \n",
            " extracting: /inbreast/roi/51049080.roi  \n",
            " extracting: /inbreast/roi/22614405.roi  \n",
            " extracting: /inbreast/xml/20587638.xml  \n",
            " extracting: /inbreast/roi/50993697.roi  \n",
            " extracting: /inbreast/roi/50997026.roi  \n",
            " extracting: /inbreast/xml/30011850.xml  \n",
            " extracting: /inbreast/xml/51049516.xml  \n",
            " extracting: /inbreast/roi/50994535.roi  \n",
            " extracting: /inbreast/xml/20588510.xml  \n",
            " extracting: /inbreast/xml/53580692.xml  \n",
            " extracting: /inbreast/roi/50998059.roi  \n",
            " extracting: /inbreast/roi/22670324.roi  \n",
            " extracting: /inbreast/roi/53582476.roi  \n",
            " extracting: /inbreast/roi/20587638.roi  \n",
            " extracting: /inbreast/xml/53582422.xml  \n",
            " extracting: /inbreast/xml/51049682.xml  \n",
            " extracting: /inbreast/xml/53587508.xml  \n",
            " extracting: /inbreast/roi/24058686.roi  \n",
            " extracting: /inbreast/xml/20586908.xml  \n",
            " extracting: /inbreast/roi/22670278.roi  \n",
            " extracting: /inbreast/xml/22579893.xml  \n",
            " extracting: /inbreast/xml/20588562.xml  \n",
            " extracting: /inbreast/xml/50997742.xml  \n",
            " extracting: /inbreast/roi/50998494.roi  \n",
            " extracting: /inbreast/roi/50996137.roi  \n",
            " extracting: /inbreast/roi/50996709.roi  \n",
            " extracting: /inbreast/xml/53586778.xml  \n",
            " extracting: /inbreast/xml/22614545.xml  \n",
            " extracting: /inbreast/roi/50996854.roi  \n",
            " extracting: /inbreast/xml/22678646.xml  \n",
            " extracting: /inbreast/roi/53587131.roi  \n",
            " extracting: /inbreast/roi/50994616.roi  \n",
            " extracting: /inbreast/xml/22670124.xml  \n",
            " extracting: /inbreast/roi/22579754.roi  \n",
            " extracting: /inbreast/xml/24065407.xml  \n",
            " extracting: /inbreast/xml/50993841.xml  \n",
            " extracting: /inbreast/roi/22580015.roi  \n",
            " extracting: /inbreast/roi/22580341.roi  \n",
            " extracting: /inbreast/roi/50993922.roi  \n",
            " extracting: /inbreast/xml/50997796.xml  \n",
            " extracting: /inbreast/xml/50994589.xml  \n",
            " extracting: /inbreast/roi/53587427.roi  \n",
            " extracting: /inbreast/roi/22678787.roi  \n",
            " extracting: /inbreast/roi/20587994.roi  \n",
            " extracting: /inbreast/roi/24065761.roi  \n",
            " extracting: /inbreast/xml/51049489.xml  \n",
            " extracting: /inbreast/xml/20587928.xml  \n",
            " extracting: /inbreast/xml/53586987.xml  \n",
            " extracting: /inbreast/roi/24065557.roi  \n",
            " extracting: /inbreast/roi/22678495.roi  \n",
            " extracting: /inbreast/xml/51049249.xml  \n",
            " extracting: /inbreast/roi/24058712.roi  \n",
            " extracting: /inbreast/roi/22671003.roi  \n",
            " extracting: /inbreast/roi/50998440.roi  \n",
            " extracting: /inbreast/roi/20587466.roi  \n",
            " extracting: /inbreast/xml/50997434.xml  \n",
            " extracting: /inbreast/xml/53580858.xml  \n",
            " extracting: /inbreast/xml/24055355.xml  \n",
            " extracting: /inbreast/xml/20587054.xml  \n",
            " extracting: /inbreast/xml/22678856.xml  \n",
            " extracting: /inbreast/roi/24058660.roi  \n",
            " extracting: /inbreast/xml/50996736.xml  \n",
            " extracting: /inbreast/roi/50995789.roi  \n",
            " extracting: /inbreast/roi/24065860.roi  \n",
            " extracting: /inbreast/xml/22678833.xml  \n",
            " extracting: /inbreast/roi/22614568.roi  \n",
            " extracting: /inbreast/roi/22670094.roi  \n",
            " extracting: /inbreast/roi/20588510.roi  \n",
            " extracting: /inbreast/roi/22580038.roi  \n",
            " extracting: /inbreast/xml/50998204.xml  \n",
            " extracting: /inbreast/roi/20587320.roi  \n",
            " extracting: /inbreast/roi/53587041.roi  \n",
            " extracting: /inbreast/xml/50997651.xml  \n",
            " extracting: /inbreast/xml/22670177.xml  \n",
            " extracting: /inbreast/roi/22614499.roi  \n",
            " extracting: /inbreast/roi/22670809.roi  \n",
            " extracting: /inbreast/roi/24055355.roi  \n",
            " extracting: /inbreast/roi/24065434.roi  \n",
            " extracting: /inbreast/xml/22678953.xml  \n",
            " extracting: /inbreast/xml/53587599.xml  \n",
            " extracting: /inbreast/xml/24065289.xml  \n",
            " extracting: /inbreast/roi/50996056.roi  \n",
            " extracting: /inbreast/xml/22613650.xml  \n",
            " extracting: /inbreast/xml/22678694.xml  \n",
            " extracting: /inbreast/roi/50999094.roi  \n",
            " extracting: /inbreast/xml/50998634.xml  \n",
            " extracting: /inbreast/xml/22678495.xml  \n",
            " extracting: /inbreast/xml/53582683.xml  \n",
            " extracting: /inbreast/roi/50997769.roi  \n",
            " extracting: /inbreast/roi/22580244.roi  \n",
            " extracting: /inbreast/roi/53587104.roi  \n",
            " extracting: /inbreast/xml/20586934.xml  \n",
            " extracting: /inbreast/xml/24055654.xml  \n",
            " extracting: /inbreast/xml/22613624.xml  \n",
            " extracting: /inbreast/xml/50993922.xml  \n",
            " extracting: /inbreast/xml/24055752.xml  \n",
            " extracting: /inbreast/roi/22579893.roi  \n",
            " extracting: /inbreast/xml/50999300.xml  \n",
            " extracting: /inbreast/xml/22670147.xml  \n",
            " extracting: /inbreast/roi/20587346.roi  \n",
            " extracting: /inbreast/xml/20587372.xml  \n",
            " extracting: /inbreast/roi/50997742.roi  \n",
            " extracting: /inbreast/roi/50994562.roi  \n",
            " extracting: /inbreast/roi/24065914.roi  \n",
            " extracting: /inbreast/xml/22427864.xml  \n",
            " extracting: /inbreast/roi/24058738.roi  \n",
            " extracting: /inbreast/roi/24065680.roi  \n",
            " extracting: /inbreast/xml/50999432.xml  \n",
            " extracting: /inbreast/xml/26933859.xml  \n",
            " extracting: /inbreast/xml/22580244.xml  \n",
            " extracting: /inbreast/xml/22613918.xml  \n",
            " extracting: /inbreast/xml/51049276.xml  \n",
            " extracting: /inbreast/roi/24055958.roi  \n",
            " extracting: /inbreast/roi/22678518.roi  \n",
            " extracting: /inbreast/roi/22613770.roi  \n",
            " extracting: /inbreast/roi/20587372.roi  \n",
            " extracting: /inbreast/xml/51048945.xml  \n",
            " extracting: /inbreast/xml/53587014.xml  \n",
            " extracting: /inbreast/xml/22613676.xml  \n",
            " extracting: /inbreast/xml/22580341.xml  \n",
            " extracting: /inbreast/roi/20586960.roi  \n",
            " extracting: /inbreast/xml/22614266.xml  \n",
            " extracting: /inbreast/roi/20588020.roi  \n",
            " extracting: /inbreast/roi/22579916.roi  \n",
            " extracting: /inbreast/roi/50998113.roi  \n",
            " extracting: /inbreast/roi/24055627.roi  \n",
            " extracting: /inbreast/xml/53580611.xml  \n",
            " extracting: /inbreast/roi/24055149.roi  \n",
            " extracting: /inbreast/xml/22613702.xml  \n",
            " extracting: /inbreast/xml/20587758.xml  \n",
            " extracting: /inbreast/xml/51048891.xml  \n",
            " extracting: /inbreast/xml/53580638.xml  \n",
            " extracting: /inbreast/xml/22580015.xml  \n",
            " extracting: /inbreast/xml/24055024.xml  \n",
            " extracting: /inbreast/xml/20586960.xml  \n",
            " extracting: /inbreast/roi/50997515.roi  \n",
            " extracting: /inbreast/xml/30011647.xml  \n",
            " extracting: /inbreast/roi/22679008.roi  \n",
            " extracting: /inbreast/roi/50998204.roi  \n",
            " extracting: /inbreast/roi/20587928.roi  \n",
            " extracting: /inbreast/xml/22579847.xml  \n",
            " extracting: /inbreast/roi/22580654.roi  \n",
            " extracting: /inbreast/xml/22580192.xml  \n",
            " extracting: /inbreast/roi/24055806.roi  \n",
            " extracting: /inbreast/xml/50997597.xml  \n",
            " extracting: /inbreast/roi/20587664.roi  \n",
            " extracting: /inbreast/roi/50998177.roi  \n",
            " extracting: /inbreast/roi/22678694.roi  \n",
            " extracting: /inbreast/xml/22670809.xml  \n",
            " extracting: /inbreast/roi/53580885.roi  \n",
            " extracting: /inbreast/xml/22679036.xml  \n",
            " extracting: /inbreast/xml/50998113.xml  \n",
            " extracting: /inbreast/xml/24065611.xml  \n",
            " extracting: /inbreast/roi/50999008.roi  \n",
            " extracting: /inbreast/roi/50993787.roi  \n",
            " extracting: /inbreast/xml/24055149.xml  \n",
            " extracting: /inbreast/xml/51049053.xml  \n",
            " extracting: /inbreast/xml/50994535.xml  \n",
            " extracting: /inbreast/xml/22580576.xml  \n",
            " extracting: /inbreast/roi/26933801.roi  \n",
            " extracting: /inbreast/xml/22579730.xml  \n",
            " extracting: /inbreast/roi/50997277.roi  \n",
            " extracting: /inbreast/xml/24065707.xml  \n",
            " extracting: /inbreast/roi/22613918.roi  \n",
            " extracting: /inbreast/xml/22580654.xml  \n",
            " extracting: /inbreast/roi/20587784.roi  \n",
            " extracting: /inbreast/xml/50998413.xml  \n",
            " extracting: /inbreast/roi/22579870.roi  \n",
            " extracting: /inbreast/roi/50993814.roi  \n",
            " extracting: /inbreast/roi/50999300.roi  \n",
            " extracting: /inbreast/roi/51070197.roi  \n",
            " extracting: /inbreast/roi/22614545.roi  \n",
            " extracting: /inbreast/roi/24065380.roi  \n",
            " extracting: /inbreast/xml/53582710.xml  \n",
            " extracting: /inbreast/roi/22580367.roi  \n",
            " extracting: /inbreast/roi/53580831.roi  \n",
            " extracting: /inbreast/roi/53582791.roi  \n",
            " extracting: /inbreast/roi/24055445.roi  \n",
            " extracting: /inbreast/xml/50995762.xml  \n",
            " extracting: /inbreast/roi/50997134.roi  \n",
            " extracting: /inbreast/roi/51049134.roi  \n",
            " extracting: /inbreast/xml/20587784.xml  \n",
            " extracting: /inbreast/roi/53587014.roi  \n",
            " extracting: /inbreast/xml/24065734.xml  \n",
            " extracting: /inbreast/xml/51048972.xml  \n",
            " extracting: /inbreast/xml/24065680.xml  \n",
            " extracting: /inbreast/roi/50994164.roi  \n",
            " extracting: /inbreast/xml/51049134.xml  \n",
            " extracting: /inbreast/roi/22670620.roi  \n",
            " extracting: /inbreast/roi/51049655.roi  \n",
            " extracting: /inbreast/xml/50997823.xml  \n",
            " extracting: /inbreast/roi/50996881.roi  \n",
            " extracting: /inbreast/xml/20587612.xml  \n",
            " extracting: /inbreast/xml/50994110.xml  \n",
            " extracting: /inbreast/xml/50993868.xml  \n",
            " extracting: /inbreast/roi/50993868.roi  \n",
            " extracting: /inbreast/roi/50996972.roi  \n",
            " extracting: /inbreast/roi/20587054.roi  \n",
            " extracting: /inbreast/xml/26933830.xml  \n",
            " extracting: /inbreast/xml/50996881.xml  \n",
            " extracting: /inbreast/xml/20587810.xml  \n",
            " extracting: /inbreast/xml/50993787.xml  \n",
            " extracting: /inbreast/xml/20587492.xml  \n",
            " extracting: /inbreast/xml/50994381.xml  \n",
            " extracting: /inbreast/xml/50999246.xml  \n",
            " extracting: /inbreast/roi/51049682.roi  \n",
            " extracting: /inbreast/roi/50993949.roi  \n",
            " extracting: /inbreast/xml/22678787.xml  \n",
            " extracting: /inbreast/roi/22614074.roi  \n",
            " extracting: /inbreast/roi/50994110.roi  \n",
            " extracting: /inbreast/xml/50997223.xml  \n",
            " extracting: /inbreast/roi/50997223.roi  \n",
            " extracting: /inbreast/roi/50998467.roi  \n",
            " extracting: /inbreast/roi/53581887.roi  \n",
            " extracting: /inbreast/xml/53587131.xml  \n",
            " extracting: /inbreast/roi/51048738.roi  \n",
            " extracting: /inbreast/roi/51048945.roi  \n",
            " extracting: /inbreast/roi/30011507.roi  \n",
            " extracting: /inbreast/roi/51048891.roi  \n",
            " extracting: /inbreast/xml/22580068.xml  \n",
            " extracting: /inbreast/xml/50994841.xml  \n",
            " extracting: /inbreast/xml/53586869.xml  \n",
            " extracting: /inbreast/xml/53580831.xml  \n",
            " extracting: /inbreast/xml/50997026.xml  \n",
            " extracting: /inbreast/xml/50998032.xml  \n",
            " extracting: /inbreast/roi/20588536.roi  \n",
            " extracting: /inbreast/xml/20587174.xml  \n",
            " extracting: /inbreast/xml/50993895.xml  \n",
            " extracting: /inbreast/roi/24065289.roi  \n",
            " extracting: /inbreast/xml/50996228.xml  \n",
            " extracting: /inbreast/xml/24065914.xml  \n",
            " extracting: /inbreast/roi/50993643.roi  \n",
            " extracting: /inbreast/xml/50994273.xml  \n",
            " extracting: /inbreast/roi/20588046.roi  \n",
            " extracting: /inbreast/xml/50999148.xml  \n",
            " extracting: /inbreast/xml/22670855.xml  \n",
            " extracting: /inbreast/roi/20588680.roi  \n",
            " extracting: /inbreast/xml/24055176.xml  \n",
            " extracting: /inbreast/roi/50995963.roi  \n",
            " extracting: /inbreast/xml/50996406.xml  \n",
            " extracting: /inbreast/roi/53582656.roi  \n",
            " extracting: /inbreast/roi/50996228.roi  \n",
            " extracting: /inbreast/roi/51049516.roi  \n",
            " extracting: /inbreast/roi/50994589.roi  \n",
            " extracting: /inbreast/xml/24055877.xml  \n",
            " extracting: /inbreast/roi/30318067.roi  \n",
            " extracting: /inbreast/xml/20588334.xml  \n",
            " extracting: /inbreast/xml/22580732.xml  \n",
            " extracting: /inbreast/roi/53586724.roi  \n",
            " extracting: /inbreast/xml/22579870.xml  \n",
            " extracting: /inbreast/roi/22670511.roi  \n",
            " extracting: /inbreast/xml/22427705.xml  \n",
            " extracting: /inbreast/xml/22670278.xml  \n",
            " extracting: /inbreast/xml/20586986.xml  \n",
            " extracting: /inbreast/xml/50997304.xml  \n",
            " extracting: /inbreast/roi/24055328.roi  \n",
            " extracting: /inbreast/xml/22613770.xml  \n",
            " extracting: /inbreast/xml/50996800.xml  \n",
            " extracting: /inbreast/roi/51049489.roi  \n",
            " extracting: /inbreast/roi/51049628.roi  \n",
            " extracting: /inbreast/roi/20587174.roi  \n",
            " extracting: /inbreast/roi/22427705.roi  \n",
            " extracting: /inbreast/roi/24065461.roi  \n",
            " extracting: /inbreast/roi/53586987.roi  \n",
            " extracting: /inbreast/xml/50996972.xml  \n",
            " extracting: /inbreast/xml/50994164.xml  \n",
            " extracting: /inbreast/xml/22580367.xml  \n",
            " extracting: /inbreast/xml/30011700.xml  \n",
            " extracting: /inbreast/roi/50998231.roi  \n",
            " extracting: /inbreast/xml/24055078.xml  \n",
            " extracting: /inbreast/xml/50995963.xml  \n",
            " extracting: /inbreast/xml/24055600.xml  \n",
            " extracting: /inbreast/xml/20588536.xml  \n",
            " extracting: /inbreast/roi/50996800.roi  \n",
            " extracting: /inbreast/xml/50996056.xml  \n",
            " extracting: /inbreast/roi/22678810.roi  \n",
            " extracting: /inbreast/xml/50998086.xml  \n",
            " extracting: /inbreast/xml/22670324.xml  \n",
            " extracting: /inbreast/roi/20588072.roi  \n",
            " extracting: /inbreast/roi/53581941.roi  \n",
            " extracting: /inbreast/xml/53587717.xml  \n",
            " extracting: /inbreast/xml/20587902.xml  \n",
            " extracting: /inbreast/xml/53586805.xml  \n",
            " extracting: /inbreast/xml/20588046.xml  \n",
            " extracting: /inbreast/roi/22580520.roi  \n",
            " extracting: /inbreast/xml/20587466.xml  \n",
            " extracting: /inbreast/roi/26933859.roi  \n",
            " extracting: /inbreast/xml/22671003.xml  \n",
            " extracting: /inbreast/xml/30318067.xml  \n",
            " extracting: /inbreast/xml/24065530.xml  \n",
            " extracting: /inbreast/xml/24055203.xml  \n",
            " extracting: /inbreast/roi/53580638.roi  \n",
            " extracting: /inbreast/roi/53582710.roi  \n",
            " extracting: /inbreast/roi/24055483.roi  \n",
            " extracting: /inbreast/roi/53582764.roi  \n",
            " extracting: /inbreast/roi/30011553.roi  \n",
            " extracting: /inbreast/xml/20587994.xml  \n",
            " extracting: /inbreast/xml/50993616.xml  \n",
            " extracting: /inbreast/xml/22614097.xml  \n",
            " extracting: /inbreast/xml/24065584.xml  \n",
            " extracting: /inbreast/roi/50994381.roi  \n",
            " extracting: /inbreast/xml/51049543.xml  \n",
            " extracting: /inbreast/xml/50997515.xml  \n",
            " extracting: /inbreast/xml/51049628.xml  \n",
            " extracting: /inbreast/roi/20587492.roi  \n",
            " extracting: /inbreast/xml/53586724.xml  \n",
            " extracting: /inbreast/xml/24058712.xml  \n",
            " extracting: /inbreast/roi/22579730.roi  \n",
            " extracting: /inbreast/xml/22427840.xml  \n",
            " extracting: /inbreast/xml/24055573.xml  \n",
            " extracting: /inbreast/roi/53586869.roi  \n",
            " extracting: /inbreast/xml/50998981.xml  \n",
            " extracting: /inbreast/xml/20587200.xml  \n",
            " extracting: /inbreast/xml/20587226.xml  \n",
            " extracting: /inbreast/roi/50994300.roi  \n",
            " extracting: /inbreast/roi/22580732.roi  \n",
            " extracting: /inbreast/xml/20588072.xml  \n",
            " extracting: /inbreast/xml/24055958.xml  \n",
            " extracting: /inbreast/xml/50996709.xml  \n",
            " extracting: /inbreast/roi/30011824.roi  \n",
            " extracting: /inbreast/roi/50998032.roi  \n",
            " extracting: /inbreast/roi/50994327.roi  \n",
            " extracting: /inbreast/xml/30011674.xml  \n",
            " extracting: /inbreast/xml/24065887.xml  \n",
            " extracting: /inbreast/roi/24065734.roi  \n",
            " extracting: /inbreast/xml/53581941.xml  \n",
            " extracting: /inbreast/xml/51048918.xml  \n",
            " extracting: /inbreast/xml/53580885.xml  \n",
            " extracting: /inbreast/roi/50996945.roi  \n",
            " extracting: /inbreast/roi/27829188.roi  \n",
            " extracting: /inbreast/roi/51048765.roi  \n",
            " extracting: /inbreast/roi/50997461.roi  \n",
            " extracting: /inbreast/xml/22678810.xml  \n",
            " extracting: /inbreast/xml/51048765.xml  \n",
            " extracting: /inbreast/xml/22613796.xml  \n",
            " extracting: /inbreast/xml/20587148.xml  \n",
            " extracting: /inbreast/roi/50999432.roi  \n",
            " extracting: /inbreast/roi/50996110.roi  \n",
            " extracting: /inbreast/roi/50993426.roi  \n",
            " extracting: /inbreast/roi/51049249.roi  \n",
            " extracting: /inbreast/roi/22614353.roi  \n",
            " extracting: /inbreast/xml/22679008.xml  \n",
            " extracting: /inbreast/roi/50997250.roi  \n",
            " extracting: /inbreast/roi/50994354.roi  \n",
            " extracting: /inbreast/xml/24055627.xml  \n",
            " extracting: /inbreast/roi/50994273.roi  \n",
            " extracting: /inbreast/xml/22614568.xml  \n",
            " extracting: /inbreast/xml/24058738.xml  \n",
            " extracting: /inbreast/roi/50995990.roi  \n",
            " extracting: /inbreast/roi/24065584.roi  \n",
            " extracting: /inbreast/roi/30011798.roi  \n",
            " extracting: /inbreast/roi/53586896.roi  \n",
            " extracting: /inbreast/xml/20587518.xml  \n",
            " extracting: /inbreast/xml/22580680.xml  \n",
            " extracting: /inbreast/roi/51048918.roi  \n",
            " extracting: /inbreast/xml/50993399.xml  \n",
            " extracting: /inbreast/xml/24065434.xml  \n",
            " extracting: /inbreast/roi/50993616.roi  \n",
            " extracting: /inbreast/xml/22580520.xml  \n",
            " extracting: /inbreast/roi/22580098.roi  \n",
            " extracting: /inbreast/xml/26933801.xml  \n",
            " extracting: /inbreast/xml/22614431.xml  \n",
            " extracting: /inbreast/xml/22614150.xml  \n",
            " extracting: /inbreast/xml/30011798.xml  \n",
            " extracting: /inbreast/roi/24065833.roi  \n",
            " extracting: /inbreast/roi/50997107.roi  \n",
            " extracting: /inbreast/xml/24065860.xml  \n",
            " extracting: /inbreast/roi/20586986.roi  \n",
            " extracting: /inbreast/roi/50997597.roi  \n",
            " extracting: /inbreast/roi/50994841.roi  \n",
            " extracting: /inbreast/xml/50997277.xml  \n",
            " extracting: /inbreast/xml/30011824.xml  \n",
            " extracting: /inbreast/roi/53582683.roi  \n",
            " extracting: /inbreast/roi/22678980.roi  \n",
            " extracting: /inbreast/xml/53580665.xml  \n",
            " extracting: /inbreast/roi/50997823.roi  \n",
            " extracting: /inbreast/roi/20588562.roi  \n",
            " extracting: /inbreast/roi/53586960.roi  \n",
            " extracting: /inbreast/xml/50994562.xml  \n",
            " extracting: /inbreast/roi/24065887.roi  \n",
            " extracting: /inbreast/xml/22670301.xml  \n",
            " extracting: /inbreast/xml/50997134.xml  \n",
            " extracting: /inbreast/roi/22614522.roi  \n",
            " extracting: /inbreast/roi/30011530.roi  \n",
            " extracting: /inbreast/roi/53587454.roi  \n",
            " extracting: /inbreast/xml/24065461.xml  \n",
            " extracting: /inbreast/xml/20587080.xml  \n",
            " extracting: /inbreast/roi/22580680.roi  \n",
            " extracting: /inbreast/roi/20587518.roi  \n",
            " extracting: /inbreast/roi/22614127.roi  \n",
            " extracting: /inbreast/xml/50993670.xml  \n",
            " extracting: /inbreast/roi/53582818.roi  \n",
            " extracting: /inbreast/roi/20587200.roi  \n",
            " extracting: /inbreast/xml/22614405.xml  \n",
            " extracting: /inbreast/roi/50997304.roi  \n",
            " extracting: /inbreast/xml/24055931.xml  \n",
            " extracting: /inbreast/dicom/read_mixed_csv.m  \n",
            " extracting: /inbreast/dicom/inbreastBuilder.m  \n",
            " extracting: /inbreast/dicom/50997597_67cc8c9939d74a9a_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065289_c4b995eddb3c510c_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996056_71c1a60d57c5322f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998177_f34ee0ab6591b792_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581060_4c341dad22471922_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998413_1f139436acfc5467_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582818_465aa5ec1b59efc6_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055958_839819f2eadaf325_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055654_6f1aef40b3775182_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580068_6200187f3f1ccc18_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587758_81cd83d2f4d78528_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055877_839819f2eadaf325_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670832_0b7396cdccacca82_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581433_b231a8ba4dd4214f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065584_d8205a09c8173f44_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580192_5530d5782fc89dd7_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588562_bf1a6aaadb05e3df_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670511_7e677f3d530e41ed_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/27829215_fbb55bf7fff48540_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24058686_9e8db9e34d5275ef_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993868_de5e8d61e501a71b_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/26933801_f8bfddc28e8045c0_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586442_dda3c6969a34ff8e_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580492_2a5b932da4ce5ca1_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670347_98429c0bdf78c0c7_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055328_1e10aef17c9fe149_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049276_832ebce700241036_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614379_d065adcb9905b973_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055078_2f1104b3cda7f145_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670278_98429c0bdf78c0c7_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994535_de4c34099d6ef8de_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587080_b6a4f750c6df4f90_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582683_465aa5ec1b59efc6_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049489_6f64793857feb5d0_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/27829161_fbb55bf7fff48540_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587131_7b71aa9928e6975e_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997080_ce5e5e18a261cd29_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049655_6f64793857feb5d0_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993922_de5e8d61e501a71b_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999175_cb65e8dac169f596_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613822_45c7f44839fd9e68_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22427840_bbd6a3a35438c11b_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996800_fdf4a1516f88b280_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613702_dcafa6ba6374ec07_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993949_de5e8d61e501a71b_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065557_d8205a09c8173f44_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22579893_301f1776aebbf5d2_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065380_83db89f57aea498a_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055779_f0f1a133837b5137_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587294_e634830794f5c1bd_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613970_f23fa352e7de3dc7_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587744_5fb370d4c1c71974_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613848_45c7f44839fd9e68_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588164_8d0b9620c53c0268_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587902_8dbbd4e51f549ff0_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/26933830_f8bfddc28e8045c0_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588654_036aff49b8ac84f0_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22427864_bbd6a3a35438c11b_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999273_cb65e8dac169f596_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996379_6aba0b402889a16f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670094_e1f51192f7bf3f5f_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996201_8c1b2bd64ca4d778_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580098_6200187f3f1ccc18_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587572_11e6732579acf692_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586415_dda3c6969a34ff8e_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50995963_d742ec2f9b90aa62_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588138_8d0b9620c53c0268_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587690_f4b2d377f43ba0bd_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588458_bf1a6aaadb05e3df_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998634_cd12bc20b3d27d0b_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580611_40e22f2e3215b954_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055752_f0f1a133837b5137_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994868_069212ec65a94339_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998349_1e4b534393d18753_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055931_839819f2eadaf325_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997769_cbb6c98a81e69eeb_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997624_67cc8c9939d74a9a_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993814_de5e8d61e501a71b_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678980_b9a4da5f2dae63a9_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587664_f4b2d377f43ba0bd_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614097_6bd24a0a42c19ce1_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586751_e5f3f68b9ce31228_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670442_7e677f3d530e41ed_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065308_c4b995eddb3c510c_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998258_f34ee0ab6591b792_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24054997_2f1104b3cda7f145_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994327_cc9e66c5b31baab8_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581151_3be876aecfaad4ca_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678856_64a22c47765f0c5c_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582567_3e73f1c0670cfb0a_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580732_fe7d005dcbbfb46d_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055149_606e9b184978a350_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588020_024ee3569b2605dc_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678694_61b13c59bcba149e_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582395_3f0db31711fc9795_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581237_80123a24997098dc_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24058660_9e8db9e34d5275ef_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580548_2a5b932da4ce5ca1_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049628_6f64793857feb5d0_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993976_de5e8d61e501a71b_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582791_465aa5ec1b59efc6_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670301_98429c0bdf78c0c7_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998231_f34ee0ab6591b792_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996406_6aba0b402889a16f_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996709_330e5fe16929eed4_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580654_fe7d005dcbbfb46d_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614353_d065adcb9905b973_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011530_349323117bf0fd93_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678518_60995d51033e24b8_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998607_cd12bc20b3d27d0b_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581006_4c341dad22471922_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581887_21e6cc12630e5e9f_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587104_7b71aa9928e6975e_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582304_8913a7e0cf3bd74e_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587663_5fb370d4c1c71974_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049249_832ebce700241036_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581460_b231a8ba4dd4214f_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997026_ce5e5e18a261cd29_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678495_60995d51033e24b8_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50995899_c94d8a1ebd452afe_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065833_c01f83a1eb283270_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065761_5291e1aee2bbf5df_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065611_d8205a09c8173f44_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587372_e634830794f5c1bd_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582656_465aa5ec1b59efc6_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22427705_d713ef5849f98b6c_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614405_d065adcb9905b973_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997053_ce5e5e18a261cd29_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055600_6f1aef40b3775182_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613624_dcafa6ba6374ec07_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581769_573747ee33ef6e5a_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049516_6f64793857feb5d0_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994589_de4c34099d6ef8de_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994733_069212ec65a94339_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50995872_c94d8a1ebd452afe_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22579754_bbd6a3a35438c11b_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998467_1f139436acfc5467_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670643_e15a16f87b4f9782_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996736_330e5fe16929eed4_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22579916_301f1776aebbf5d2_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994110_cc9e66c5b31baab8_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065734_5291e1aee2bbf5df_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586960_809e3f43339f93c6_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613996_f23fa352e7de3dc7_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670878_0b7396cdccacca82_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678449_60995d51033e24b8_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065251_c4b995eddb3c510c_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670620_e15a16f87b4f9782_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586724_e5f3f68b9ce31228_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997277_9054942f7be52dd9_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581406_b231a8ba4dd4214f_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588216_8d0b9620c53c0268_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999327_cb65e8dac169f596_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588308_493155e17143edef_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580804_51bec6477a7898b9_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999246_cb65e8dac169f596_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049682_6f64793857feb5d0_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998059_66adfbb4f19c76d2_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614150_6bd24a0a42c19ce1_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587014_809e3f43339f93c6_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994273_cc9e66c5b31baab8_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588190_8d0b9620c53c0268_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996352_6aba0b402889a16f_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51048945_f3e93e889a7746f0_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670673_e15a16f87b4f9782_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011824_4f20c1285d8f0b1f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065707_5291e1aee2bbf5df_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996972_ce5e5e18a261cd29_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580393_5eae9beae14d26fd_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996999_ce5e5e18a261cd29_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678670_61b13c59bcba149e_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580858_51bec6477a7898b9_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670703_e15a16f87b4f9782_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999121_cb65e8dac169f596_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22679036_b9a4da5f2dae63a9_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586361_dda3c6969a34ff8e_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998113_66adfbb4f19c76d2_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678472_60995d51033e24b8_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582764_465aa5ec1b59efc6_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055483_ac3185e18ffdc7b6_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22427682_d713ef5849f98b6c_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580885_51bec6477a7898b9_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581860_21e6cc12630e5e9f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582710_465aa5ec1b59efc6_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998440_1f139436acfc5467_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670488_7e677f3d530e41ed_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581379_b231a8ba4dd4214f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587836_81cd83d2f4d78528_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587226_fd746d25eb40b3dc_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994895_069212ec65a94339_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/27829134_fbb55bf7fff48540_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614266_1e5c3af078f74b05_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678810_64a22c47765f0c5c_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011850_4f20c1285d8f0b1f_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580692_40e22f2e3215b954_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613918_f23fa352e7de3dc7_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998322_1e4b534393d18753_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670809_0b7396cdccacca82_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22579730_bbd6a3a35438c11b_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614074_6bd24a0a42c19ce1_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582476_3f0db31711fc9795_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587174_fd746d25eb40b3dc_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20586986_6c613a14b80a8591_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997742_cbb6c98a81e69eeb_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580706_fe7d005dcbbfb46d_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22579847_301f1776aebbf5d2_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20586960_6c613a14b80a8591_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993670_b03f1dd34eb3c55f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51048918_f3e93e889a7746f0_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614236_1e5c3af078f74b05_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011507_349323117bf0fd93_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055445_ac3185e18ffdc7b6_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993895_de5e8d61e501a71b_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999459_f62fbf38fb208316_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586987_809e3f43339f93c6_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997107_ce5e5e18a261cd29_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996854_fdf4a1516f88b280_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678787_64a22c47765f0c5c_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055203_606e9b184978a350_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998494_1f139436acfc5467_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613770_45c7f44839fd9e68_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51048972_f3e93e889a7746f0_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580680_fe7d005dcbbfb46d_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588536_bf1a6aaadb05e3df_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678622_61b13c59bcba149e_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997250_9054942f7be52dd9_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065530_d8205a09c8173f44_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587492_d571b5880ad2a016_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996827_fdf4a1516f88b280_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999094_cb65e8dac169f596_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055051_2f1104b3cda7f145_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055627_6f1aef40b3775182_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580576_2a5b932da4ce5ca1_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670177_e1f51192f7bf3f5f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055725_f0f1a133837b5137_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587427_d2befe622e188943_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996325_6aba0b402889a16f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996228_8c1b2bd64ca4d778_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997823_cbb6c98a81e69eeb_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996881_fdf4a1516f88b280_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20586908_6c613a14b80a8591_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582422_3f0db31711fc9795_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587518_d571b5880ad2a016_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587054_b6a4f750c6df4f90_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/27829188_fbb55bf7fff48540_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998661_cd12bc20b3d27d0b_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587148_fd746d25eb40b3dc_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614522_2dec4948fbe6336d_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581941_21e6cc12630e5e9f_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997488_97ec8cadfca70d32_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582331_8913a7e0cf3bd74e_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580270_5530d5782fc89dd7_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587481_d2befe622e188943_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049134_8c105bb715bf1c3c_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20586934_6c613a14b80a8591_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50995789_0c735e8768d276b4_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587928_8dbbd4e51f549ff0_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22579870_301f1776aebbf5d2_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065434_83db89f57aea498a_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581033_4c341dad22471922_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996083_71c1a60d57c5322f_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51048891_f3e93e889a7746f0_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011647_6968748e66837bc7_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22679008_b9a4da5f2dae63a9_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613796_45c7f44839fd9e68_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588510_bf1a6aaadb05e3df_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614568_2dec4948fbe6336d_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51048765_3f22cdda8da215e3_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613944_f23fa352e7de3dc7_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587599_11e6732579acf692_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065407_83db89f57aea498a_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580638_40e22f2e3215b954_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587508_d2befe622e188943_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670978_f571fd4e63c718e3_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587690_5fb370d4c1c71974_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049080_8c105bb715bf1c3c_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994164_cc9e66c5b31baab8_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065270_c4b995eddb3c510c_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055464_ac3185e18ffdc7b6_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580831_51bec6477a7898b9_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614431_d065adcb9905b973_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055573_6f1aef40b3775182_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998086_66adfbb4f19c76d2_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587346_e634830794f5c1bd_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993643_b03f1dd34eb3c55f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996137_71c1a60d57c5322f_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587810_81cd83d2f4d78528_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587784_81cd83d2f4d78528_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581796_573747ee33ef6e5a_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993399_5d85ecc9cf26b254_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587320_e634830794f5c1bd_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994137_cc9e66c5b31baab8_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994300_cc9e66c5b31baab8_MG_R_FB_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055904_839819f2eadaf325_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587612_f4b2d377f43ba0bd_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580244_5530d5782fc89dd7_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065914_c01f83a1eb283270_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580520_2a5b932da4ce5ca1_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999008_a78eba834ef6ee88_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997515_97ec8cadfca70d32_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580038_6200187f3f1ccc18_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588680_036aff49b8ac84f0_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587638_f4b2d377f43ba0bd_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580218_5530d5782fc89dd7_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678833_64a22c47765f0c5c_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993616_b03f1dd34eb3c55f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581914_21e6cc12630e5e9f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993841_de5e8d61e501a71b_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999300_cb65e8dac169f596_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670147_e1f51192f7bf3f5f_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586805_e5f3f68b9ce31228_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581124_3be876aecfaad4ca_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994760_069212ec65a94339_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588046_024ee3569b2605dc_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586388_dda3c6969a34ff8e_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587544_d571b5880ad2a016_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055176_606e9b184978a350_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994191_cc9e66c5b31baab8_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994814_069212ec65a94339_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613650_dcafa6ba6374ec07_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049462_6f64793857feb5d0_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997304_9054942f7be52dd9_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997651_67cc8c9939d74a9a_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011727_6968748e66837bc7_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011674_6968748e66837bc7_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049543_6f64793857feb5d0_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994381_cc9e66c5b31baab8_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50995990_d742ec2f9b90aa62_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998032_66adfbb4f19c76d2_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24058712_9e8db9e34d5275ef_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996110_71c1a60d57c5322f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53581264_80123a24997098dc_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614127_6bd24a0a42c19ce1_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065680_5291e1aee2bbf5df_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582449_3f0db31711fc9795_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/26933772_f8bfddc28e8045c0_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055355_1e10aef17c9fe149_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678953_b9a4da5f2dae63a9_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587041_809e3f43339f93c6_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999432_f62fbf38fb208316_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997223_9054942f7be52dd9_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998204_f34ee0ab6591b792_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994408_cc9e66c5b31baab8_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670124_e1f51192f7bf3f5f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582737_465aa5ec1b59efc6_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30318067_4f20c1285d8f0b1f_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997678_67cc8c9939d74a9a_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580419_5eae9beae14d26fd_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994706_069212ec65a94339_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065461_83db89f57aea498a_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587454_d2befe622e188943_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998580_cd12bc20b3d27d0b_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24058738_9e8db9e34d5275ef_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065887_c01f83a1eb283270_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/26933859_f8bfddc28e8045c0_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055806_f0f1a133837b5137_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614499_2dec4948fbe6336d_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997134_ce5e5e18a261cd29_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50995762_0c735e8768d276b4_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670465_7e677f3d530e41ed_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586778_e5f3f68b9ce31228_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53582540_3e73f1c0670cfb0a_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580367_5eae9beae14d26fd_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580979_4c341dad22471922_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997796_cbb6c98a81e69eeb_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997434_97ec8cadfca70d32_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055024_2f1104b3cda7f145_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055382_1e10aef17c9fe149_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50998981_a78eba834ef6ee88_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586869_6ac23356b912ee9b_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994841_069212ec65a94339_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994616_de4c34099d6ef8de_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993426_5d85ecc9cf26b254_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22427751_d713ef5849f98b6c_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50999148_cb65e8dac169f596_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22671003_f571fd4e63c718e3_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588072_024ee3569b2605dc_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670855_0b7396cdccacca82_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049053_8c105bb715bf1c3c_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587466_d571b5880ad2a016_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22427728_d713ef5849f98b6c_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22678646_61b13c59bcba149e_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055274_1e10aef17c9fe149_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50996945_ce5e5e18a261cd29_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51048738_3f22cdda8da215e3_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24065860_c01f83a1eb283270_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53580665_40e22f2e3215b954_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22670324_98429c0bdf78c0c7_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580015_6200187f3f1ccc18_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51070197_6f64793857feb5d0_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993787_de5e8d61e501a71b_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994354_cc9e66c5b31baab8_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22613676_dcafa6ba6374ec07_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587994_024ee3569b2605dc_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/24055502_ac3185e18ffdc7b6_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/51049107_8c105bb715bf1c3c_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22580341_5eae9beae14d26fd_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011798_4f20c1285d8f0b1f_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20587200_fd746d25eb40b3dc_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011700_6968748e66837bc7_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011553_349323117bf0fd93_MG_L_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50997461_97ec8cadfca70d32_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53586896_6ac23356b912ee9b_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994562_de4c34099d6ef8de_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/22614545_2dec4948fbe6336d_MG_R_ML_ANON.dcm  \n",
            " extracting: /inbreast/dicom/20588334_493155e17143edef_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/30011484_349323117bf0fd93_MG_R_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50994787_069212ec65a94339_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/50993697_b03f1dd34eb3c55f_MG_L_CC_ANON.dcm  \n",
            " extracting: /inbreast/dicom/53587717_5fb370d4c1c71974_MG_R_ML_ANON.dcm  \n",
            "Loaded INBreast.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEtqI8iQjl44",
        "colab_type": "text"
      },
      "source": [
        "This is a utility for loading INBreast ROIs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSrctKwgYUIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9a9cee0-d2c6-40e8-b50e-8a7847047471"
      },
      "source": [
        "df_inbreast = pd.read_csv('../inbreast/INbreast.csv', sep=\";\")\n",
        "\n",
        "patient_scores = {}\n",
        "for i, filename in enumerate(df_inbreast['File Name']):\n",
        "  patient_scores[str(filename)] = scoring_encoding[df_inbreast['Bi-Rads'][i]]\n",
        "\n",
        "print('Loaded patient Bi-Rads scores.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded patient Bi-Rads scores.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksj31MDe07AQ",
        "colab_type": "code",
        "outputId": "be64821f-3c4c-4df2-9469-aa1eb7ea0519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def load_inbreast_mask(mask_path, imshape=(4084, 3328)):\n",
        "    \"\"\"\n",
        "    This function loads a osirix xml region as a binary numpy array for INBREAST\n",
        "    dataset\n",
        "    @mask_path : Path to the xml file\n",
        "    @imshape : The shape of the image as an array e.g. [4084, 3328]\n",
        "    return: numpy array where positions in the roi are assigned a value of 1.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    with open(mask_path, 'rb') as mask_file:\n",
        "        plist_dict = plistlib.load(mask_file, fmt=plistlib.FMT_XML)['Images'][0]\n",
        "        numRois = plist_dict['NumberOfROIs']\n",
        "        rois = plist_dict['ROIs']\n",
        "        assert len(rois) == numRois\n",
        "        for roi in rois:\n",
        "            mask = np.zeros(imshape)\n",
        "            numPoints = roi['NumberOfPoints']\n",
        "            points = roi['Point_px']\n",
        "            assert numPoints == len(points)\n",
        "            points = [eval(point) for point in points]\n",
        "            if len(points) <= 2:\n",
        "                for point in points:\n",
        "                    mask[int(point[1]), int(point[0])] = 1\n",
        "            else:\n",
        "                x, y = zip(*points)\n",
        "                col, row = np.array(x), np.array(y) ##x coord is the column coord in an image and y is the row\n",
        "                poly_x, poly_y = polygon(row, col, shape=imshape)\n",
        "                mask[poly_x, poly_y] = 1\n",
        "            # store indices for nonzero points so that patches containing tumors\n",
        "            # can be extracted\n",
        "            locations_of_interest = np.nonzero(mask)\n",
        "            coords = np.array(locations_of_interest).T\n",
        "            # x_coords, y_coords = np.nonzero(mask)\n",
        "            # x_min = np.min(x_coords)\n",
        "            # x_max = np.max(x_coords)\n",
        "            # y_min = np.min(y_coords)\n",
        "            # y_max = np.max(y_coords)\n",
        "            # if x_min == x_max:\n",
        "            #   x_min -= 5\n",
        "            #   x_max += 5\n",
        "            # if y_min == y_max:\n",
        "            #   y_min -= 5\n",
        "            #   y_max += 5\n",
        "            # bounding_box = (x_min, x_max, y_min, y_max)\n",
        "            # result.append(bounding_box)\n",
        "    return coords\n",
        "\n",
        "print('Defined INBreast ROI loading utility.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined INBreast ROI loading utility.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APKVXG7HjuCC",
        "colab_type": "text"
      },
      "source": [
        "Then we load the INBreast ROIs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PRKKnJf_-9U",
        "colab_type": "code",
        "outputId": "a92be6f0-77aa-45f1-e208-18146b0ada2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "inbreast_xml = '../inbreast/xml'\n",
        "inbreast_rois = {}\n",
        "\n",
        "files = os.listdir(inbreast_xml)\n",
        "with tqdm(total=len(files)) as t:\n",
        "  for filename in files:\n",
        "    coords = load_inbreast_mask(os.path.join(inbreast_xml, filename))\n",
        "    inbreast_rois[filename.split('.')[0]] = coords\n",
        "    t.update()\n",
        "\n",
        "print('Finished loading ROIs.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 343/343 [31:10<00:00,  5.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished loading ROIs.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrT_gpcPZTXQ",
        "colab_type": "text"
      },
      "source": [
        "We extract patches from the input as a pre-processing step, following [Agarwal et al.](https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-6/issue-03/031409/Automatic-mass-detection-in-mammograms-using-deep-convolutional-neural-networks/10.1117/1.JMI.6.3.031409.full?SSO=1) This is also where data augmentation of positive examples, through horizontal flipping and random rotation, and zero mean normalization occurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CiYjxUXiZIo",
        "colab_type": "code",
        "outputId": "dfb75498-fc8b-490b-b325-bcbc1fa3881f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "inbreast_dicom = '../inbreast/dicom'\n",
        "display = False\n",
        "N = 3000\n",
        "\n",
        "X = np.zeros((N,)+input_shape)\n",
        "Y = np.zeros((N,))\n",
        "Y_multiclass = np.zeros((N,))\n",
        "\n",
        "n = 0\n",
        "dicom_files = os.listdir(inbreast_dicom)\n",
        "random.seed(6802)\n",
        "with tqdm(total=len(dicom_files)) as t:\n",
        "  for filename in dicom_files:\n",
        "    if filename.endswith(\".dcm\"):\n",
        "      patient_image = pydicom.dcmread(os.path.join(inbreast_dicom, filename)).pixel_array\n",
        "      patient_id = filename.split('_')[0]\n",
        "      # excluding border regions\n",
        "      current_i = patch_size[0]\n",
        "      current_j = patch_size[1]\n",
        "      max_i, max_j = patient_image.shape\n",
        "      while current_i + 2*patch_size[0] < max_i:\n",
        "        if n > N:\n",
        "          break\n",
        "        next_i = current_i + patch_size[0]\n",
        "        while current_j + 2*patch_size[1] < max_j:\n",
        "          next_j = current_j + patch_size[1]\n",
        "          patch = patient_image[current_i:next_i, current_j:next_j]\n",
        "          mean, sd = cv2.meanStdDev(patch)\n",
        "          current_j = next_j\n",
        "          if sd[0,0] < 1:\n",
        "            continue\n",
        "          if patient_id in inbreast_rois:\n",
        "            positive = False\n",
        "            for x_coord, y_coord in inbreast_rois[patient_id]:\n",
        "              if current_i <= x_coord <= next_i and current_j <= y_coord <= next_j:\n",
        "                positive = True\n",
        "                break\n",
        "            if positive:\n",
        "              for i in range(5):\n",
        "                Y[n+i] = 1\n",
        "                Y_multiclass[n+i] = patient_scores[patient_id]\n",
        "            else:\n",
        "              if random.random() > 0.95:\n",
        "                Y[n] = 0\n",
        "              else:\n",
        "                continue\n",
        "          else:\n",
        "            continue\n",
        "          normalized_patch = (patch-mean)/sd\n",
        "          broadcasted_patch = normalized_patch[:, :, None] * np.ones(3, dtype=int)[None, None, :]\n",
        "          X[n] = broadcasted_patch\n",
        "          if positive: # augment data with image transformations\n",
        "            shear_map = transform.AffineTransform(shear=random.uniform(0, 0.4))\n",
        "            scale_factor = random.uniform(0.5, 1.5)\n",
        "            scale_map = transform.AffineTransform(scale=(scale_factor, scale_factor))\n",
        "            X[n+1] = cv2.flip(broadcasted_patch, 0) \n",
        "            X[n+2] = transform.rotate(broadcasted_patch, random.randint(0, 40))\n",
        "            X[n+3] = transform.warp(broadcasted_patch, inverse_map=shear_map)\n",
        "            X[n+4] = transform.warp(broadcasted_patch, inverse_map=scale_map)\n",
        "            n += 5\n",
        "          else:\n",
        "            n += 1\n",
        "        current_i = next_i\n",
        "        current_j = 0\n",
        "    t.update()\n",
        "\n",
        "X = X[:n,:,:,:]\n",
        "Y = Y[:n]\n",
        "Y_multiclass = Y_multiclass[:n]\n",
        "assert X.shape[0] == Y.shape[0] == Y_multiclass.shape[0]\n",
        "print('Number of examples:', X.shape[0])\n",
        "print('Number of positive examples:', np.sum(Y))\n",
        "for label in [0]+list(set(patient_scores.values())):\n",
        "  print('Number of examples with label {}:'.format(label), np.sum(Y_multiclass == label))\n",
        "\n",
        "print('Finished pre-processing INBreast data.')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 412/412 [08:11<00:00,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of examples: 1921\n",
            "Number of positive examples: 680.0\n",
            "Number of examples with label 1: 0\n",
            "Number of examples with label 2: 100\n",
            "Number of examples with label 3: 185\n",
            "Number of examples with label 4: 70\n",
            "Number of examples with label 5: 20\n",
            "Number of examples with label 6: 150\n",
            "Number of examples with label 7: 115\n",
            "Number of examples with label 8: 40\n",
            "Finished pre-processing INBreast data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSSzb14gkOz7",
        "colab_type": "text"
      },
      "source": [
        "Here we write the pre-processed data to a Google Drive so we can load it more easily later. You'll need to provide an authorization code when prompted, if you haven't mounted Google Drive before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdbBv_5AGILE",
        "colab_type": "code",
        "outputId": "619a2c3e-4d2b-4904-a39a-9ffe0dd10524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if not os.path.exists('gdrive/My Drive/6.802'):\n",
        "  os.mkdir('gdrive/My Drive/6.802')\n",
        "np.save('gdrive/My Drive/6.802/data.npy', X)\n",
        "np.save('gdrive/My Drive/6.802/labels.npy', Y)\n",
        "np.save('gdrive/My Drive/6.802/labels_multiclass.npy', Y_multiclass)\n",
        "\n",
        "print('Saved pre-processed data to Google Drive.')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Saved pre-processed data to Google Drive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOJyGNulRuLz",
        "colab_type": "text"
      },
      "source": [
        "## Training and Evaluation (binary classification)\n",
        "Start here if you already have pre-processed data in Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhyamANkmmq9",
        "colab_type": "text"
      },
      "source": [
        "First we'll test the GPU. Change to a GPU like this:\n",
        "\n",
        "1.   Navigate to Edit→Notebook Settings\n",
        "2.   select GPU from the Hardware Accelerator drop-down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_Sfwxcpmlg1",
        "colab_type": "code",
        "outputId": "30fa7db6-9fcb-413c-bc57-236067c99a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5H2aehalHjh",
        "colab_type": "text"
      },
      "source": [
        "Here we load the pre-processed data from Google Drive. You'll need to mount Google Drive if you haven't done so above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DMmmeJTPDJL",
        "colab_type": "code",
        "outputId": "51c7c79d-2115-4a56-9533-3c66ab26ea16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "raw_X = np.load('gdrive/My Drive/6.802/data.npy')\n",
        "raw_Y = np.load('gdrive/My Drive/6.802/labels.npy')\n",
        "\n",
        "print('Loaded pre-processed data from Google Drive.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Loaded pre-processed data from Google Drive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_s2mI35i-Q8",
        "colab_type": "text"
      },
      "source": [
        "Here we split the data into train and test sets (80-20). The training set will be split (60-20) into train and validation sets later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqBzLDnRi9pW",
        "colab_type": "code",
        "outputId": "b5158d93-efe4-4540-8e7c-49834b1c68a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit([0,1])\n",
        "binarized_labels = lb.transform(raw_Y)\n",
        "\n",
        "X, Y = shuffle(raw_X, np.hstack((binarized_labels, 1 - binarized_labels)))\n",
        "n = X.shape[0]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
        "\n",
        "print('Split data into train and test sets.')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split data into train and test sets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiNIheY615Rd",
        "colab_type": "text"
      },
      "source": [
        "We use convolutional bases pre-trained on ImageNet and fine-tune them for the mass detection task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr-kZ2_yjACh",
        "colab_type": "text"
      },
      "source": [
        "The top of the network will be custom made, and we will test various architectures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1QUdA1gi9pa",
        "colab_type": "code",
        "outputId": "4f194abe-6d78-4f11-b2bf-de0a36400fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Each function takes in a convolutional base and returns a Keras model that\n",
        "# uses the convolutional base and adds a classifier on top.\n",
        "\n",
        "def make_model_logistic(conv_base):\n",
        "  model = K.models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(K.layers.Flatten())\n",
        "  model.add(K.layers.Dense(1024, activation='relu'))\n",
        "  model.add(K.layers.Dropout(0.5))\n",
        "  model.add(K.layers.Dense(2, activation='softmax'))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer=K.optimizers.Adam(learning_rate=10e-6),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def make_model_svm(conv_base):\n",
        "  model = K.models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(K.layers.Flatten())\n",
        "  model.add(K.layers.Dense(1024))\n",
        "  model.add(K.layers.Activation('relu'))\n",
        "  model.add(K.layers.Dropout(0.5))\n",
        "  model.add(K.layers.Dense(2, kernel_regularizer=K.regularizers.l2(0.01)))\n",
        "  model.add(K.layers.Activation('linear'))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='hinge',\n",
        "                optimizer='adadelta',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "print('Defined model makers.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined model makers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGokW4b6lWET",
        "colab_type": "text"
      },
      "source": [
        "Here we train and evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdT1PwdiTm3P",
        "colab_type": "code",
        "outputId": "615b289b-afac-44ed-c5d2-d186f9db6e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def train_model(model, x_train, y_train, callbacks):\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS,\n",
        "            callbacks=[plot_losses, es]+callbacks,\n",
        "            verbose=1,\n",
        "            validation_split = 0.25)\n",
        "\n",
        "def get_results_for_model(conv_base, make_model_func, model_name, multiclass=False):\n",
        "  time_callback = TimeHistory()\n",
        "  model = make_model_func(conv_base)\n",
        "  if multiclass:\n",
        "    train_model(model, X_train, Y_multiclass_train, [time_callback, checkpointer])\n",
        "  else:\n",
        "    train_model(model, X_train, Y_train, [time_callback, checkpointer])\n",
        "  model.load_weights('weights.hdf5')\n",
        "  if multiclass:\n",
        "    Y_pred, evaluation, prediction_time = evaluate_model(model, X_test, Y_multiclass_test)\n",
        "  else:\n",
        "    Y_pred, evaluation, prediction_time = evaluate_model(model, X_test, Y_test)\n",
        "  if not multiclass:\n",
        "    print('number positive predictions:', np.sum(1-np.argmax(Y_pred,axis=1)))\n",
        "    auc = roc_auc_score(Y_test, Y_pred)\n",
        "    fpr, tpr, thresholds = roc_curve(Y_test[:,0], Y_pred[:,0])\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.plot([i/100 for i in range(100)], [i/100 for i in range(100)], color='black')\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.title('Receiver Operating Characteristic (ROC)')\n",
        "    plt.savefig('6.802/{}roc.png'.format(model_name))\n",
        "    print('AUC ROC:', auc)\n",
        "  print('loss:', evaluation[0])\n",
        "  print('accuracy:', evaluation[1])\n",
        "  print('training time:', np.sum(time_callback.times))\n",
        "  print('prediction time:', prediction_time)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  # print('VGG19, logistic classifier')\n",
        "  # get_results_for_model(vgg19_base, make_model_logistic, 'vgg19_logistic')\n",
        "  # print('VGG19, SVM classifier')\n",
        "  # get_results_for_model(vgg19_base, make_model_svm, 'vgg19_svm')\n",
        "  # print('ResNetV2, logistic classifier')\n",
        "  # get_results_for_model(resnet152vt, make_model_logistic, 'resnetv2_logistic')\n",
        "  # print('NasNetMobile, logistic classifier')\n",
        "  # get_results_for_model(nasnetmobile, make_model_logistic, 'nasnetmobile_logistic')\n",
        "  # print('DenseNet201, logistic classifier')\n",
        "  # get_results_for_model(densenet201, make_model_logistic, 'densenet201_logistic')\n",
        "  # print('MobileNetV2, logistic classifier')\n",
        "  # get_results_for_model(mobilenetv2, make_model_logistic, 'mobilenetv2_logistic')\n",
        "  # print('InceptionV3, logistic classifier')\n",
        "  # get_results_for_model(inceptionv3, make_model_logistic, 'inceptionv3_logistic')\n",
        "  print('Xception, logistic classifier')\n",
        "  # get_results_for_model(xception_base, make_model_logistic, 'xception_logistic')\n",
        "\n",
        "print('Trained and evaluated models.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xception, logistic classifier\n",
            "Trained and evaluated models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4bZp6ihvtjE",
        "colab_type": "text"
      },
      "source": [
        "Here we perform grid search over the number of layers to freeze for the best performing architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUak5WeTvzYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "415a1097-75d4-446f-9441-5e09c52f1ab0"
      },
      "source": [
        "def grid_search(base):\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  training_times = []\n",
        "  to_freeze = []\n",
        "  num_params = []\n",
        "  conv_base = make_conv_base(base)\n",
        "  for num_to_freeze in range(len(conv_base.layers)):\n",
        "    for layer in conv_base.layers[:num_to_freeze]:\n",
        "      layer.trainable = False\n",
        "    model = make_model_logistic(conv_base)\n",
        "    num_params.append(int(\n",
        "      np.sum([K.backend.count_params(p) for p in model.trainable_weights])\n",
        "    ))\n",
        "    time_callback = TimeHistory()\n",
        "    history = model.fit(X_train, Y_train,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=EPOCHS,\n",
        "            callbacks=[es, time_callback],\n",
        "            verbose=1,\n",
        "            validation_split = 0.25)\n",
        "    best_accuracy = max(history.history['accuracy'])\n",
        "    best_validation_loss = min(history.history['val_loss'])\n",
        "    losses.append(best_validation_loss)\n",
        "    accuracies.append(best_accuracy)\n",
        "    training_times.append(np.sum(time_callback.times))\n",
        "    conv_base = make_conv_base(base)\n",
        "    to_freeze.append(num_to_freeze)\n",
        "  return losses, accuracies, training_times, to_freeze\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  losses, accuracies, training_times, to_freeze = grid_search(vgg19.VGG19)\n",
        "  ig, axs = plt.subplots(1, 3, figsize=(16,5))\n",
        "  axs[0].plot(to_freeze, losses)\n",
        "  axs[0].title.set_text('Validation Loss')\n",
        "  axs[0].set_xlabel('Number of Frozen Layers')\n",
        "  axs[1].plot(to_freeze, accuracies)\n",
        "  axs[1].title.set_text('Training Accuracy')\n",
        "  axs[1].set_xlabel('Number of Frozen Layers')\n",
        "  axs[2].plot(to_freeze, training_times)\n",
        "  axs[2].title.set_text('Training Time (s)')\n",
        "  axs[2].set_xlabel('Number of Frozen Layers')\n",
        "  plt.savefig('6.802/vgg19_logistic_freeze_comparison.png')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,717,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 15s 13ms/step - loss: 0.6325 - accuracy: 0.6701 - val_loss: 0.4242 - val_accuracy: 0.7995\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.4206 - accuracy: 0.8030 - val_loss: 0.3576 - val_accuracy: 0.8359\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.3571 - accuracy: 0.8307 - val_loss: 0.3474 - val_accuracy: 0.8438\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.3130 - accuracy: 0.8602 - val_loss: 0.3197 - val_accuracy: 0.8438\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.2589 - accuracy: 0.8845 - val_loss: 0.3068 - val_accuracy: 0.8568\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.2169 - accuracy: 0.9097 - val_loss: 0.3055 - val_accuracy: 0.8359\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.1457 - accuracy: 0.9436 - val_loss: 0.2998 - val_accuracy: 0.8646\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.1213 - accuracy: 0.9505 - val_loss: 0.3472 - val_accuracy: 0.8333\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.1000 - accuracy: 0.9653 - val_loss: 0.2934 - val_accuracy: 0.8620\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0563 - accuracy: 0.9826 - val_loss: 0.3142 - val_accuracy: 0.8750\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0387 - accuracy: 0.9896 - val_loss: 0.3547 - val_accuracy: 0.8542\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0209 - accuracy: 0.9983 - val_loss: 0.3683 - val_accuracy: 0.8698\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0126 - accuracy: 0.9983 - val_loss: 0.3788 - val_accuracy: 0.8698\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.4466 - val_accuracy: 0.8385\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.3766 - val_accuracy: 0.8620\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.4394 - val_accuracy: 0.8750\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.4618 - val_accuracy: 0.8568\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 0.4487 - val_accuracy: 0.8698\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0142 - accuracy: 0.9939 - val_loss: 0.5092 - val_accuracy: 0.8802\n",
            "Epoch 00019: early stopping\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,717,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 11s 10ms/step - loss: 0.6805 - accuracy: 0.6424 - val_loss: 0.4141 - val_accuracy: 0.7995\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.4172 - accuracy: 0.7995 - val_loss: 0.3656 - val_accuracy: 0.8307\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.3844 - accuracy: 0.8368 - val_loss: 0.3526 - val_accuracy: 0.8385\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.3142 - accuracy: 0.8559 - val_loss: 0.3555 - val_accuracy: 0.8229\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.2504 - accuracy: 0.8993 - val_loss: 0.3245 - val_accuracy: 0.8359\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.1929 - accuracy: 0.9175 - val_loss: 0.3043 - val_accuracy: 0.8594\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.1577 - accuracy: 0.9375 - val_loss: 0.3206 - val_accuracy: 0.8646\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.1166 - accuracy: 0.9609 - val_loss: 0.3108 - val_accuracy: 0.8594\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0746 - accuracy: 0.9774 - val_loss: 0.3195 - val_accuracy: 0.8620\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0480 - accuracy: 0.9835 - val_loss: 0.3319 - val_accuracy: 0.8490\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0626 - accuracy: 0.9783 - val_loss: 0.4876 - val_accuracy: 0.8698\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0390 - accuracy: 0.9905 - val_loss: 0.3620 - val_accuracy: 0.8802\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0172 - accuracy: 0.9965 - val_loss: 0.4289 - val_accuracy: 0.8906\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8828\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8750\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8802\n",
            "Epoch 00016: early stopping\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,715,778\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 11s 9ms/step - loss: 0.6225 - accuracy: 0.6780 - val_loss: 0.3844 - val_accuracy: 0.8229\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.4076 - accuracy: 0.8125 - val_loss: 0.3305 - val_accuracy: 0.8490\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.3229 - accuracy: 0.8325 - val_loss: 0.3170 - val_accuracy: 0.8490\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.2829 - accuracy: 0.8637 - val_loss: 0.3030 - val_accuracy: 0.8620\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.2563 - accuracy: 0.8924 - val_loss: 0.3096 - val_accuracy: 0.8594\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.2177 - accuracy: 0.9062 - val_loss: 0.2883 - val_accuracy: 0.8698\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.1760 - accuracy: 0.9375 - val_loss: 0.2861 - val_accuracy: 0.8620\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.1185 - accuracy: 0.9566 - val_loss: 0.2860 - val_accuracy: 0.8750\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0816 - accuracy: 0.9766 - val_loss: 0.2808 - val_accuracy: 0.8724\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0497 - accuracy: 0.9870 - val_loss: 0.2957 - val_accuracy: 0.8880\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.2892 - val_accuracy: 0.8906\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.2951 - val_accuracy: 0.8932\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 0.2943 - val_accuracy: 0.8672\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.3932 - val_accuracy: 0.8880\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0284 - accuracy: 0.9913 - val_loss: 0.3352 - val_accuracy: 0.8750\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0227 - accuracy: 0.9948 - val_loss: 0.3285 - val_accuracy: 0.8724\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 0.3713 - val_accuracy: 0.8698\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.4150 - val_accuracy: 0.8828\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 10s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.8854\n",
            "Epoch 00019: early stopping\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,678,850\n",
            "Non-trainable params: 38,720\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 10s 8ms/step - loss: 0.6314 - accuracy: 0.6858 - val_loss: 0.4327 - val_accuracy: 0.7969\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.3451 - val_accuracy: 0.8359\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.3447 - accuracy: 0.8307 - val_loss: 0.4167 - val_accuracy: 0.7865\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.2899 - accuracy: 0.8611 - val_loss: 0.3159 - val_accuracy: 0.8516\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.2431 - accuracy: 0.8889 - val_loss: 0.3062 - val_accuracy: 0.8828\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.1908 - accuracy: 0.9158 - val_loss: 0.2956 - val_accuracy: 0.8698\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.1621 - accuracy: 0.9340 - val_loss: 0.3061 - val_accuracy: 0.8464\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.1135 - accuracy: 0.9592 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0794 - accuracy: 0.9688 - val_loss: 0.3538 - val_accuracy: 0.8854\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0629 - accuracy: 0.9826 - val_loss: 0.3015 - val_accuracy: 0.8750\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0744 - accuracy: 0.9748 - val_loss: 0.3693 - val_accuracy: 0.8854\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0453 - accuracy: 0.9861 - val_loss: 0.3564 - val_accuracy: 0.8750\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.3888 - val_accuracy: 0.8333\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0267 - accuracy: 0.9887 - val_loss: 0.4332 - val_accuracy: 0.8906\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.4163 - val_accuracy: 0.8802\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.8854\n",
            "Epoch 00016: early stopping\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,678,850\n",
            "Non-trainable params: 38,720\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 10s 8ms/step - loss: 0.5972 - accuracy: 0.6901 - val_loss: 0.3898 - val_accuracy: 0.8229\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.3893 - accuracy: 0.8142 - val_loss: 0.3419 - val_accuracy: 0.8307\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.3155 - accuracy: 0.8707 - val_loss: 0.3104 - val_accuracy: 0.8698\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.2680 - accuracy: 0.8802 - val_loss: 0.3301 - val_accuracy: 0.8568\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.2140 - accuracy: 0.9028 - val_loss: 0.3449 - val_accuracy: 0.8307\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.1753 - accuracy: 0.9236 - val_loss: 0.2927 - val_accuracy: 0.8672\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.1261 - accuracy: 0.9523 - val_loss: 0.2948 - val_accuracy: 0.8724\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.1053 - accuracy: 0.9601 - val_loss: 0.2906 - val_accuracy: 0.8594\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0584 - accuracy: 0.9818 - val_loss: 0.3534 - val_accuracy: 0.8698\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0341 - accuracy: 0.9931 - val_loss: 0.3576 - val_accuracy: 0.8776\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.3715 - val_accuracy: 0.8698\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.3913 - val_accuracy: 0.8776\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.4294 - val_accuracy: 0.8724\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.4232 - val_accuracy: 0.8724\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.4802 - val_accuracy: 0.8802\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.4473 - val_accuracy: 0.8776\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.4867 - val_accuracy: 0.8776\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5383 - val_accuracy: 0.8542\n",
            "Epoch 00018: early stopping\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,604,994\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.6053 - accuracy: 0.6918 - val_loss: 0.3766 - val_accuracy: 0.8151\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.3909 - accuracy: 0.8194 - val_loss: 0.3650 - val_accuracy: 0.8281\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.3196 - accuracy: 0.8490 - val_loss: 0.3071 - val_accuracy: 0.8464\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.2763 - accuracy: 0.8785 - val_loss: 0.3023 - val_accuracy: 0.8568\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.2301 - accuracy: 0.9002 - val_loss: 0.2934 - val_accuracy: 0.8568\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.1675 - accuracy: 0.9314 - val_loss: 0.2724 - val_accuracy: 0.8828\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.1372 - accuracy: 0.9453 - val_loss: 0.2802 - val_accuracy: 0.8672\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.1176 - accuracy: 0.9566 - val_loss: 0.2688 - val_accuracy: 0.8932\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0663 - accuracy: 0.9818 - val_loss: 0.2932 - val_accuracy: 0.8802\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0509 - accuracy: 0.9861 - val_loss: 0.3484 - val_accuracy: 0.8828\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.2928 - val_accuracy: 0.8854\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.3746 - val_accuracy: 0.8906\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.3602 - val_accuracy: 0.8984\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.3567 - val_accuracy: 0.8750\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.3608 - val_accuracy: 0.8958\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.3627 - val_accuracy: 0.8880\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.4096 - val_accuracy: 0.8750\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.4142 - val_accuracy: 0.8932\n",
            "Epoch 00018: early stopping\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,457,410\n",
            "Non-trainable params: 260,160\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6568 - accuracy: 0.6710 - val_loss: 0.4363 - val_accuracy: 0.7995\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.4256 - accuracy: 0.7925 - val_loss: 0.3457 - val_accuracy: 0.8281\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.3419 - accuracy: 0.8507 - val_loss: 0.3309 - val_accuracy: 0.8464\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.2762 - accuracy: 0.8759 - val_loss: 0.3175 - val_accuracy: 0.8385\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.2166 - accuracy: 0.9115 - val_loss: 0.2891 - val_accuracy: 0.8646\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1785 - accuracy: 0.9219 - val_loss: 0.3230 - val_accuracy: 0.8385\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1270 - accuracy: 0.9505 - val_loss: 0.3211 - val_accuracy: 0.8620\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1218 - accuracy: 0.9488 - val_loss: 0.3622 - val_accuracy: 0.8281\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0779 - accuracy: 0.9748 - val_loss: 0.3654 - val_accuracy: 0.8724\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0501 - accuracy: 0.9896 - val_loss: 0.3385 - val_accuracy: 0.8594\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0307 - accuracy: 0.9931 - val_loss: 0.3761 - val_accuracy: 0.8802\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.3608 - val_accuracy: 0.8698\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.3548 - val_accuracy: 0.8828\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 0.4111 - val_accuracy: 0.8802\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8776\n",
            "Epoch 00015: early stopping\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,457,410\n",
            "Non-trainable params: 260,160\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6353 - accuracy: 0.6823 - val_loss: 0.4031 - val_accuracy: 0.8073\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.4337 - accuracy: 0.8012 - val_loss: 0.3572 - val_accuracy: 0.8229\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.3337 - accuracy: 0.8446 - val_loss: 0.3386 - val_accuracy: 0.8151\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.2694 - accuracy: 0.8872 - val_loss: 0.3190 - val_accuracy: 0.8438\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.2193 - accuracy: 0.9002 - val_loss: 0.3232 - val_accuracy: 0.8672\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1675 - accuracy: 0.9358 - val_loss: 0.3097 - val_accuracy: 0.8750\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1085 - accuracy: 0.9592 - val_loss: 0.3068 - val_accuracy: 0.8620\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0800 - accuracy: 0.9705 - val_loss: 0.3243 - val_accuracy: 0.8698\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0633 - accuracy: 0.9818 - val_loss: 0.3259 - val_accuracy: 0.8958\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0406 - accuracy: 0.9878 - val_loss: 0.3275 - val_accuracy: 0.9010\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0227 - accuracy: 0.9957 - val_loss: 0.3449 - val_accuracy: 0.9010\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.4120 - val_accuracy: 0.8828\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.4401 - val_accuracy: 0.8620\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 0.4201 - val_accuracy: 0.8750\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.4662 - val_accuracy: 0.8906\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.5299 - val_accuracy: 0.8854\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.8906\n",
            "Epoch 00017: early stopping\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 45,162,242\n",
            "Non-trainable params: 555,328\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.5830 - accuracy: 0.7040 - val_loss: 0.3963 - val_accuracy: 0.8203\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.3987 - accuracy: 0.8177 - val_loss: 0.3645 - val_accuracy: 0.8307\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.3272 - accuracy: 0.8550 - val_loss: 0.3636 - val_accuracy: 0.8099\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.3055 - accuracy: 0.8568 - val_loss: 0.3010 - val_accuracy: 0.8724\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.2441 - accuracy: 0.8845 - val_loss: 0.2989 - val_accuracy: 0.8568\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1838 - accuracy: 0.9227 - val_loss: 0.3040 - val_accuracy: 0.8542\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1540 - accuracy: 0.9401 - val_loss: 0.2818 - val_accuracy: 0.8750\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.1192 - accuracy: 0.9557 - val_loss: 0.3082 - val_accuracy: 0.8750\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0807 - accuracy: 0.9809 - val_loss: 0.3295 - val_accuracy: 0.8802\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0612 - accuracy: 0.9826 - val_loss: 0.3428 - val_accuracy: 0.8724\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.3397 - val_accuracy: 0.8698\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0287 - accuracy: 0.9948 - val_loss: 0.3429 - val_accuracy: 0.8828\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.4002 - val_accuracy: 0.8698\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.3894 - val_accuracy: 0.8672\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0124 - accuracy: 0.9991 - val_loss: 0.4403 - val_accuracy: 0.8880\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 0.4224 - val_accuracy: 0.8620\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.8802\n",
            "Epoch 00017: early stopping\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 44,572,162\n",
            "Non-trainable params: 1,145,408\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 8s 7ms/step - loss: 0.6885 - accuracy: 0.6155 - val_loss: 0.4388 - val_accuracy: 0.7995\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.4696 - accuracy: 0.7821 - val_loss: 0.3822 - val_accuracy: 0.8229\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.4133 - accuracy: 0.8082 - val_loss: 0.3775 - val_accuracy: 0.8229\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.3512 - accuracy: 0.8359 - val_loss: 0.3370 - val_accuracy: 0.8359\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2971 - accuracy: 0.8628 - val_loss: 0.3352 - val_accuracy: 0.8307\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2637 - accuracy: 0.8715 - val_loss: 0.3418 - val_accuracy: 0.8099\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2291 - accuracy: 0.8906 - val_loss: 0.3276 - val_accuracy: 0.8568\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1674 - accuracy: 0.9358 - val_loss: 0.3576 - val_accuracy: 0.8490\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1575 - accuracy: 0.9427 - val_loss: 0.3401 - val_accuracy: 0.8203\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1143 - accuracy: 0.9497 - val_loss: 0.3538 - val_accuracy: 0.8698\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0735 - accuracy: 0.9783 - val_loss: 0.3850 - val_accuracy: 0.8411\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0584 - accuracy: 0.9861 - val_loss: 0.4168 - val_accuracy: 0.8672\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.4363 - val_accuracy: 0.8568\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0282 - accuracy: 0.9939 - val_loss: 0.4551 - val_accuracy: 0.8438\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0176 - accuracy: 0.9983 - val_loss: 0.4602 - val_accuracy: 0.8307\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0146 - accuracy: 0.9991 - val_loss: 0.5783 - val_accuracy: 0.8672\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.5188 - val_accuracy: 0.8594\n",
            "Epoch 00017: early stopping\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 43,982,082\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.9159 - accuracy: 0.5720 - val_loss: 0.5605 - val_accuracy: 0.6302\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.5084 - accuracy: 0.7448 - val_loss: 0.4070 - val_accuracy: 0.8073\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.3872 - accuracy: 0.8220 - val_loss: 0.3444 - val_accuracy: 0.8203\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.3249 - accuracy: 0.8568 - val_loss: 0.3262 - val_accuracy: 0.8464\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2801 - accuracy: 0.8819 - val_loss: 0.3222 - val_accuracy: 0.8568\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2098 - accuracy: 0.9175 - val_loss: 0.3052 - val_accuracy: 0.8516\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1584 - accuracy: 0.9384 - val_loss: 0.3089 - val_accuracy: 0.8594\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1247 - accuracy: 0.9488 - val_loss: 0.3005 - val_accuracy: 0.8698\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0848 - accuracy: 0.9679 - val_loss: 0.3500 - val_accuracy: 0.8568\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0550 - accuracy: 0.9852 - val_loss: 0.3364 - val_accuracy: 0.8698\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0403 - accuracy: 0.9905 - val_loss: 0.3790 - val_accuracy: 0.8672\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.3738 - val_accuracy: 0.8776\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0243 - accuracy: 0.9948 - val_loss: 0.4102 - val_accuracy: 0.8802\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0165 - accuracy: 0.9983 - val_loss: 0.4154 - val_accuracy: 0.8828\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.4112 - val_accuracy: 0.8724\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8854\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.8854\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.4770 - val_accuracy: 0.8750\n",
            "Epoch 00018: early stopping\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 43,392,002\n",
            "Non-trainable params: 2,325,568\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.5783 - accuracy: 0.6979 - val_loss: 0.3863 - val_accuracy: 0.8177\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.3741 - accuracy: 0.8229 - val_loss: 0.3526 - val_accuracy: 0.8411\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.3173 - accuracy: 0.8646 - val_loss: 0.3397 - val_accuracy: 0.8099\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2472 - accuracy: 0.8993 - val_loss: 0.3384 - val_accuracy: 0.8568\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2168 - accuracy: 0.9036 - val_loss: 0.2968 - val_accuracy: 0.8542\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1704 - accuracy: 0.9401 - val_loss: 0.2868 - val_accuracy: 0.8776\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1217 - accuracy: 0.9575 - val_loss: 0.2837 - val_accuracy: 0.8672\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1125 - accuracy: 0.9575 - val_loss: 0.2965 - val_accuracy: 0.8490\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0843 - accuracy: 0.9670 - val_loss: 0.2934 - val_accuracy: 0.8828\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0562 - accuracy: 0.9835 - val_loss: 0.3015 - val_accuracy: 0.8724\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0343 - accuracy: 0.9957 - val_loss: 0.3846 - val_accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0293 - accuracy: 0.9939 - val_loss: 0.3815 - val_accuracy: 0.8802\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.4396 - val_accuracy: 0.8828\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0192 - accuracy: 0.9974 - val_loss: 0.4199 - val_accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.3996 - val_accuracy: 0.8776\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.4021 - val_accuracy: 0.8594\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.8724\n",
            "Epoch 00017: early stopping\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 43,392,002\n",
            "Non-trainable params: 2,325,568\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.5777 - accuracy: 0.7127 - val_loss: 0.3757 - val_accuracy: 0.8307\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.3777 - accuracy: 0.8290 - val_loss: 0.3465 - val_accuracy: 0.8411\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.3092 - accuracy: 0.8672 - val_loss: 0.3123 - val_accuracy: 0.8542\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2637 - accuracy: 0.8854 - val_loss: 0.3791 - val_accuracy: 0.7943\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.2155 - accuracy: 0.9019 - val_loss: 0.3209 - val_accuracy: 0.8594\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1707 - accuracy: 0.9219 - val_loss: 0.2911 - val_accuracy: 0.8490\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1750 - accuracy: 0.9219 - val_loss: 0.3182 - val_accuracy: 0.8359\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.1018 - accuracy: 0.9653 - val_loss: 0.2983 - val_accuracy: 0.8646\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0811 - accuracy: 0.9740 - val_loss: 0.3553 - val_accuracy: 0.8750\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0547 - accuracy: 0.9870 - val_loss: 0.3096 - val_accuracy: 0.8776\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0329 - accuracy: 0.9957 - val_loss: 0.3141 - val_accuracy: 0.8646\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0216 - accuracy: 0.9974 - val_loss: 0.3369 - val_accuracy: 0.8568\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0162 - accuracy: 0.9991 - val_loss: 0.3456 - val_accuracy: 0.8594\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0141 - accuracy: 0.9983 - val_loss: 0.3595 - val_accuracy: 0.8802\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.3954 - val_accuracy: 0.8724\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.8672\n",
            "Epoch 00016: early stopping\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 42,211,842\n",
            "Non-trainable params: 3,505,728\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 0.6900 - accuracy: 0.6441 - val_loss: 0.4155 - val_accuracy: 0.8125\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.4520 - accuracy: 0.7856 - val_loss: 0.3677 - val_accuracy: 0.8359\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.3585 - accuracy: 0.8299 - val_loss: 0.3391 - val_accuracy: 0.8385\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.3102 - accuracy: 0.8602 - val_loss: 0.3178 - val_accuracy: 0.8542\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.2480 - accuracy: 0.8819 - val_loss: 0.3241 - val_accuracy: 0.8672\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.2058 - accuracy: 0.9097 - val_loss: 0.3072 - val_accuracy: 0.8646\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.1553 - accuracy: 0.9410 - val_loss: 0.2846 - val_accuracy: 0.8698\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.1108 - accuracy: 0.9566 - val_loss: 0.3128 - val_accuracy: 0.8802\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0855 - accuracy: 0.9731 - val_loss: 0.3111 - val_accuracy: 0.8776\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0616 - accuracy: 0.9818 - val_loss: 0.3200 - val_accuracy: 0.8750\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0357 - accuracy: 0.9939 - val_loss: 0.3575 - val_accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0251 - accuracy: 0.9965 - val_loss: 0.3792 - val_accuracy: 0.8854\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0231 - accuracy: 0.9957 - val_loss: 0.3817 - val_accuracy: 0.8724\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0177 - accuracy: 0.9974 - val_loss: 0.4003 - val_accuracy: 0.8802\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.8776\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.8802\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8828\n",
            "Epoch 00017: early stopping\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 39,852,034\n",
            "Non-trainable params: 5,865,536\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.6600 - accuracy: 0.6606 - val_loss: 0.4282 - val_accuracy: 0.7995\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.4320 - accuracy: 0.7960 - val_loss: 0.3767 - val_accuracy: 0.8281\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.3654 - accuracy: 0.8325 - val_loss: 0.3245 - val_accuracy: 0.8438\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.3084 - accuracy: 0.8516 - val_loss: 0.3118 - val_accuracy: 0.8672\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.2537 - accuracy: 0.8941 - val_loss: 0.2961 - val_accuracy: 0.8672\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.1906 - accuracy: 0.9201 - val_loss: 0.2965 - val_accuracy: 0.8672\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.1587 - accuracy: 0.9366 - val_loss: 0.3066 - val_accuracy: 0.8516\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.1253 - accuracy: 0.9531 - val_loss: 0.3072 - val_accuracy: 0.8776\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0953 - accuracy: 0.9661 - val_loss: 0.3141 - val_accuracy: 0.8698\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0719 - accuracy: 0.9809 - val_loss: 0.3169 - val_accuracy: 0.8542\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0524 - accuracy: 0.9887 - val_loss: 0.3647 - val_accuracy: 0.8828\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0410 - accuracy: 0.9922 - val_loss: 0.3553 - val_accuracy: 0.8464\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0292 - accuracy: 0.9939 - val_loss: 0.3757 - val_accuracy: 0.8672\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.8594\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0191 - accuracy: 0.9974 - val_loss: 0.4254 - val_accuracy: 0.8776\n",
            "Epoch 00015: early stopping\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 37,492,226\n",
            "Non-trainable params: 8,225,344\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.6613 - accuracy: 0.6536 - val_loss: 0.4106 - val_accuracy: 0.7969\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.4269 - accuracy: 0.8082 - val_loss: 0.3615 - val_accuracy: 0.8203\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.3471 - accuracy: 0.8498 - val_loss: 0.3263 - val_accuracy: 0.8438\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.2808 - accuracy: 0.8793 - val_loss: 0.3283 - val_accuracy: 0.8385\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.2366 - accuracy: 0.8950 - val_loss: 0.3167 - val_accuracy: 0.8620\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.2078 - accuracy: 0.9071 - val_loss: 0.3184 - val_accuracy: 0.8359\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.1650 - accuracy: 0.9366 - val_loss: 0.2918 - val_accuracy: 0.8724\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.1269 - accuracy: 0.9549 - val_loss: 0.2908 - val_accuracy: 0.8646\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0878 - accuracy: 0.9766 - val_loss: 0.2974 - val_accuracy: 0.8672\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0730 - accuracy: 0.9818 - val_loss: 0.2996 - val_accuracy: 0.8724\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0581 - accuracy: 0.9870 - val_loss: 0.3559 - val_accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0545 - accuracy: 0.9852 - val_loss: 0.3646 - val_accuracy: 0.8464\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0294 - accuracy: 0.9974 - val_loss: 0.3379 - val_accuracy: 0.8802\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0245 - accuracy: 0.9974 - val_loss: 0.3600 - val_accuracy: 0.8854\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0196 - accuracy: 0.9983 - val_loss: 0.3728 - val_accuracy: 0.8724\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.3998 - val_accuracy: 0.8776\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.8828\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.8750\n",
            "Epoch 00018: early stopping\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 35,132,418\n",
            "Non-trainable params: 10,585,152\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.6463 - accuracy: 0.6493 - val_loss: 0.4120 - val_accuracy: 0.8151\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4607 - accuracy: 0.7856 - val_loss: 0.3593 - val_accuracy: 0.8281\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3837 - accuracy: 0.8194 - val_loss: 0.3309 - val_accuracy: 0.8411\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3128 - accuracy: 0.8568 - val_loss: 0.3204 - val_accuracy: 0.8542\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2860 - accuracy: 0.8724 - val_loss: 0.2964 - val_accuracy: 0.8724\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2246 - accuracy: 0.9089 - val_loss: 0.2907 - val_accuracy: 0.8698\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1929 - accuracy: 0.9227 - val_loss: 0.3049 - val_accuracy: 0.8750\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1665 - accuracy: 0.9306 - val_loss: 0.2865 - val_accuracy: 0.8620\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1460 - accuracy: 0.9497 - val_loss: 0.2848 - val_accuracy: 0.8724\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1075 - accuracy: 0.9679 - val_loss: 0.2842 - val_accuracy: 0.8724\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1022 - accuracy: 0.9705 - val_loss: 0.2838 - val_accuracy: 0.8776\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0796 - accuracy: 0.9818 - val_loss: 0.3000 - val_accuracy: 0.8620\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0613 - accuracy: 0.9852 - val_loss: 0.3120 - val_accuracy: 0.8854\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0509 - accuracy: 0.9913 - val_loss: 0.3031 - val_accuracy: 0.8490\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0477 - accuracy: 0.9922 - val_loss: 0.2967 - val_accuracy: 0.8802\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0361 - accuracy: 0.9931 - val_loss: 0.3169 - val_accuracy: 0.8802\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0251 - accuracy: 0.9974 - val_loss: 0.3115 - val_accuracy: 0.8776\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0223 - accuracy: 0.9974 - val_loss: 0.3295 - val_accuracy: 0.8828\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0195 - accuracy: 0.9965 - val_loss: 0.3318 - val_accuracy: 0.8750\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.8828\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 0.3614 - val_accuracy: 0.8750\n",
            "Epoch 00021: early stopping\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 35,132,418\n",
            "Non-trainable params: 10,585,152\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.6512 - accuracy: 0.6528 - val_loss: 0.4238 - val_accuracy: 0.8021\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.3660 - val_accuracy: 0.8255\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3570 - accuracy: 0.8290 - val_loss: 0.3352 - val_accuracy: 0.8411\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3158 - accuracy: 0.8464 - val_loss: 0.3210 - val_accuracy: 0.8542\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2613 - accuracy: 0.8872 - val_loss: 0.3050 - val_accuracy: 0.8568\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2335 - accuracy: 0.9002 - val_loss: 0.2944 - val_accuracy: 0.8750\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2078 - accuracy: 0.9149 - val_loss: 0.2841 - val_accuracy: 0.8750\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1602 - accuracy: 0.9401 - val_loss: 0.2957 - val_accuracy: 0.8516\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1397 - accuracy: 0.9488 - val_loss: 0.2867 - val_accuracy: 0.8802\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1142 - accuracy: 0.9583 - val_loss: 0.2817 - val_accuracy: 0.8698\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0980 - accuracy: 0.9644 - val_loss: 0.2873 - val_accuracy: 0.8776\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0718 - accuracy: 0.9783 - val_loss: 0.2872 - val_accuracy: 0.8724\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0615 - accuracy: 0.9878 - val_loss: 0.3168 - val_accuracy: 0.8411\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0502 - accuracy: 0.9887 - val_loss: 0.3139 - val_accuracy: 0.8542\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0375 - accuracy: 0.9948 - val_loss: 0.3126 - val_accuracy: 0.8776\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0285 - accuracy: 0.9991 - val_loss: 0.3075 - val_accuracy: 0.8646\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0231 - accuracy: 0.9991 - val_loss: 0.3264 - val_accuracy: 0.8646\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0189 - accuracy: 0.9974 - val_loss: 0.3358 - val_accuracy: 0.8672\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.8594\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.8724\n",
            "Epoch 00020: early stopping\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 32,772,610\n",
            "Non-trainable params: 12,944,960\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 6s 5ms/step - loss: 0.7649 - accuracy: 0.6181 - val_loss: 0.4756 - val_accuracy: 0.7943\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.3787 - val_accuracy: 0.8203\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4016 - accuracy: 0.8038 - val_loss: 0.3495 - val_accuracy: 0.8255\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3496 - accuracy: 0.8281 - val_loss: 0.3354 - val_accuracy: 0.8359\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3143 - accuracy: 0.8533 - val_loss: 0.3161 - val_accuracy: 0.8490\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2674 - accuracy: 0.8785 - val_loss: 0.3048 - val_accuracy: 0.8594\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2301 - accuracy: 0.9028 - val_loss: 0.2981 - val_accuracy: 0.8594\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2131 - accuracy: 0.9097 - val_loss: 0.2879 - val_accuracy: 0.8672\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1772 - accuracy: 0.9340 - val_loss: 0.3110 - val_accuracy: 0.8438\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1679 - accuracy: 0.9323 - val_loss: 0.2939 - val_accuracy: 0.8750\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1324 - accuracy: 0.9523 - val_loss: 0.2904 - val_accuracy: 0.8594\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1125 - accuracy: 0.9653 - val_loss: 0.2985 - val_accuracy: 0.8750\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0963 - accuracy: 0.9696 - val_loss: 0.2855 - val_accuracy: 0.8828\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0895 - accuracy: 0.9748 - val_loss: 0.2957 - val_accuracy: 0.8594\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.2999 - val_accuracy: 0.8750\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0604 - accuracy: 0.9826 - val_loss: 0.3024 - val_accuracy: 0.8776\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0496 - accuracy: 0.9905 - val_loss: 0.3105 - val_accuracy: 0.8776\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0381 - accuracy: 0.9974 - val_loss: 0.3115 - val_accuracy: 0.8724\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0344 - accuracy: 0.9974 - val_loss: 0.3259 - val_accuracy: 0.8828\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.8854\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0264 - accuracy: 0.9965 - val_loss: 0.3475 - val_accuracy: 0.8802\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0226 - accuracy: 0.9991 - val_loss: 0.3448 - val_accuracy: 0.8568\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.8542\n",
            "Epoch 00023: early stopping\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 30,412,802\n",
            "Non-trainable params: 15,304,768\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6631 - accuracy: 0.6606 - val_loss: 0.4415 - val_accuracy: 0.8021\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4827 - accuracy: 0.7795 - val_loss: 0.3866 - val_accuracy: 0.8177\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3953 - accuracy: 0.8194 - val_loss: 0.3662 - val_accuracy: 0.8333\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3611 - accuracy: 0.8264 - val_loss: 0.3649 - val_accuracy: 0.8307\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3352 - accuracy: 0.8490 - val_loss: 0.3425 - val_accuracy: 0.8385\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2869 - accuracy: 0.8741 - val_loss: 0.3308 - val_accuracy: 0.8464\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2675 - accuracy: 0.8889 - val_loss: 0.3305 - val_accuracy: 0.8411\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2420 - accuracy: 0.9019 - val_loss: 0.3213 - val_accuracy: 0.8594\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2103 - accuracy: 0.9123 - val_loss: 0.3192 - val_accuracy: 0.8359\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1953 - accuracy: 0.9227 - val_loss: 0.3102 - val_accuracy: 0.8594\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1806 - accuracy: 0.9358 - val_loss: 0.2991 - val_accuracy: 0.8568\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1584 - accuracy: 0.9436 - val_loss: 0.2991 - val_accuracy: 0.8594\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1496 - accuracy: 0.9488 - val_loss: 0.3094 - val_accuracy: 0.8438\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1276 - accuracy: 0.9618 - val_loss: 0.3158 - val_accuracy: 0.8385\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1187 - accuracy: 0.9653 - val_loss: 0.2976 - val_accuracy: 0.8672\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1048 - accuracy: 0.9696 - val_loss: 0.3072 - val_accuracy: 0.8542\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0962 - accuracy: 0.9705 - val_loss: 0.2961 - val_accuracy: 0.8594\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0813 - accuracy: 0.9826 - val_loss: 0.3016 - val_accuracy: 0.8724\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0718 - accuracy: 0.9852 - val_loss: 0.3094 - val_accuracy: 0.8307\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0711 - accuracy: 0.9844 - val_loss: 0.3073 - val_accuracy: 0.8411\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0616 - accuracy: 0.9896 - val_loss: 0.3107 - val_accuracy: 0.8594\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0552 - accuracy: 0.9878 - val_loss: 0.3313 - val_accuracy: 0.8750\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0469 - accuracy: 0.9957 - val_loss: 0.3137 - val_accuracy: 0.8620\n",
            "Epoch 24/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0400 - accuracy: 0.9983 - val_loss: 0.3148 - val_accuracy: 0.8542\n",
            "Epoch 25/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0374 - accuracy: 0.9983 - val_loss: 0.3162 - val_accuracy: 0.8698\n",
            "Epoch 26/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0292 - accuracy: 0.9991 - val_loss: 0.3148 - val_accuracy: 0.8568\n",
            "Epoch 27/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.0279 - accuracy: 0.9991 - val_loss: 0.3238 - val_accuracy: 0.8620\n",
            "Epoch 00027: early stopping\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 28,052,994\n",
            "Non-trainable params: 17,664,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7264 - accuracy: 0.6137 - val_loss: 0.4712 - val_accuracy: 0.7734\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5044 - accuracy: 0.7431 - val_loss: 0.4073 - val_accuracy: 0.8151\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.3807 - val_accuracy: 0.8203\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4023 - accuracy: 0.8168 - val_loss: 0.3614 - val_accuracy: 0.8255\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3643 - accuracy: 0.8394 - val_loss: 0.3482 - val_accuracy: 0.8307\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3314 - accuracy: 0.8411 - val_loss: 0.3407 - val_accuracy: 0.8385\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3036 - accuracy: 0.8602 - val_loss: 0.3412 - val_accuracy: 0.8490\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3018 - accuracy: 0.8698 - val_loss: 0.3242 - val_accuracy: 0.8516\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2728 - accuracy: 0.8724 - val_loss: 0.3219 - val_accuracy: 0.8542\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2554 - accuracy: 0.8932 - val_loss: 0.3121 - val_accuracy: 0.8594\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2364 - accuracy: 0.9045 - val_loss: 0.3076 - val_accuracy: 0.8698\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2149 - accuracy: 0.9184 - val_loss: 0.3033 - val_accuracy: 0.8672\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2054 - accuracy: 0.9297 - val_loss: 0.3011 - val_accuracy: 0.8646\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1814 - accuracy: 0.9271 - val_loss: 0.2964 - val_accuracy: 0.8646\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1875 - accuracy: 0.9314 - val_loss: 0.2914 - val_accuracy: 0.8646\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1738 - accuracy: 0.9418 - val_loss: 0.2890 - val_accuracy: 0.8672\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1609 - accuracy: 0.9453 - val_loss: 0.2885 - val_accuracy: 0.8724\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1450 - accuracy: 0.9523 - val_loss: 0.2959 - val_accuracy: 0.8438\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1417 - accuracy: 0.9523 - val_loss: 0.3031 - val_accuracy: 0.8411\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1285 - accuracy: 0.9609 - val_loss: 0.2937 - val_accuracy: 0.8385\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1157 - accuracy: 0.9679 - val_loss: 0.2864 - val_accuracy: 0.8672\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1099 - accuracy: 0.9679 - val_loss: 0.2882 - val_accuracy: 0.8750\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1061 - accuracy: 0.9740 - val_loss: 0.2843 - val_accuracy: 0.8776\n",
            "Epoch 24/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0976 - accuracy: 0.9748 - val_loss: 0.2885 - val_accuracy: 0.8802\n",
            "Epoch 25/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0942 - accuracy: 0.9800 - val_loss: 0.2881 - val_accuracy: 0.8646\n",
            "Epoch 26/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0832 - accuracy: 0.9809 - val_loss: 0.2905 - val_accuracy: 0.8724\n",
            "Epoch 27/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0777 - accuracy: 0.9852 - val_loss: 0.2952 - val_accuracy: 0.8464\n",
            "Epoch 28/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0701 - accuracy: 0.9870 - val_loss: 0.2909 - val_accuracy: 0.8646\n",
            "Epoch 29/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0694 - accuracy: 0.9896 - val_loss: 0.2927 - val_accuracy: 0.8750\n",
            "Epoch 30/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0640 - accuracy: 0.9878 - val_loss: 0.2972 - val_accuracy: 0.8490\n",
            "Epoch 31/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0594 - accuracy: 0.9905 - val_loss: 0.2934 - val_accuracy: 0.8568\n",
            "Epoch 32/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0586 - accuracy: 0.9922 - val_loss: 0.2969 - val_accuracy: 0.8620\n",
            "Epoch 33/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.0524 - accuracy: 0.9931 - val_loss: 0.3024 - val_accuracy: 0.8776\n",
            "Epoch 00033: early stopping\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 45,717,570\n",
            "Trainable params: 25,693,186\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.7505 - accuracy: 0.5903 - val_loss: 0.5223 - val_accuracy: 0.7839\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5486 - accuracy: 0.7257 - val_loss: 0.4389 - val_accuracy: 0.7969\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4590 - accuracy: 0.7917 - val_loss: 0.3940 - val_accuracy: 0.8125\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4165 - accuracy: 0.8099 - val_loss: 0.3823 - val_accuracy: 0.8099\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3914 - accuracy: 0.8247 - val_loss: 0.3704 - val_accuracy: 0.8151\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3631 - accuracy: 0.8273 - val_loss: 0.3570 - val_accuracy: 0.8229\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3587 - accuracy: 0.8325 - val_loss: 0.3575 - val_accuracy: 0.8385\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3355 - accuracy: 0.8516 - val_loss: 0.3495 - val_accuracy: 0.8229\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3161 - accuracy: 0.8516 - val_loss: 0.3420 - val_accuracy: 0.8255\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3293 - accuracy: 0.8507 - val_loss: 0.3362 - val_accuracy: 0.8281\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2967 - accuracy: 0.8646 - val_loss: 0.3395 - val_accuracy: 0.8464\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2978 - accuracy: 0.8681 - val_loss: 0.3456 - val_accuracy: 0.8542\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2796 - accuracy: 0.8802 - val_loss: 0.3295 - val_accuracy: 0.8542\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2707 - accuracy: 0.8793 - val_loss: 0.3299 - val_accuracy: 0.8542\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2613 - accuracy: 0.8889 - val_loss: 0.3379 - val_accuracy: 0.8542\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2484 - accuracy: 0.8976 - val_loss: 0.3308 - val_accuracy: 0.8542\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2420 - accuracy: 0.8967 - val_loss: 0.3321 - val_accuracy: 0.8542\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2424 - accuracy: 0.9019 - val_loss: 0.3154 - val_accuracy: 0.8620\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2263 - accuracy: 0.9062 - val_loss: 0.3247 - val_accuracy: 0.8594\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2147 - accuracy: 0.9175 - val_loss: 0.3176 - val_accuracy: 0.8516\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2248 - accuracy: 0.9054 - val_loss: 0.3220 - val_accuracy: 0.8568\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2133 - accuracy: 0.9158 - val_loss: 0.3067 - val_accuracy: 0.8672\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1994 - accuracy: 0.9288 - val_loss: 0.3078 - val_accuracy: 0.8568\n",
            "Epoch 24/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1900 - accuracy: 0.9314 - val_loss: 0.3224 - val_accuracy: 0.8438\n",
            "Epoch 25/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1955 - accuracy: 0.9280 - val_loss: 0.3307 - val_accuracy: 0.8359\n",
            "Epoch 26/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1948 - accuracy: 0.9314 - val_loss: 0.3160 - val_accuracy: 0.8438\n",
            "Epoch 27/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1773 - accuracy: 0.9436 - val_loss: 0.3132 - val_accuracy: 0.8542\n",
            "Epoch 28/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1770 - accuracy: 0.9436 - val_loss: 0.3064 - val_accuracy: 0.8620\n",
            "Epoch 29/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1695 - accuracy: 0.9418 - val_loss: 0.3235 - val_accuracy: 0.8359\n",
            "Epoch 30/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1684 - accuracy: 0.9462 - val_loss: 0.3114 - val_accuracy: 0.8385\n",
            "Epoch 31/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1588 - accuracy: 0.9505 - val_loss: 0.3045 - val_accuracy: 0.8646\n",
            "Epoch 32/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1562 - accuracy: 0.9523 - val_loss: 0.3037 - val_accuracy: 0.8672\n",
            "Epoch 33/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1489 - accuracy: 0.9549 - val_loss: 0.3018 - val_accuracy: 0.8672\n",
            "Epoch 34/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1453 - accuracy: 0.9601 - val_loss: 0.3014 - val_accuracy: 0.8646\n",
            "Epoch 35/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1488 - accuracy: 0.9566 - val_loss: 0.3077 - val_accuracy: 0.8438\n",
            "Epoch 36/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1461 - accuracy: 0.9540 - val_loss: 0.3297 - val_accuracy: 0.8333\n",
            "Epoch 37/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1486 - accuracy: 0.9575 - val_loss: 0.3152 - val_accuracy: 0.8411\n",
            "Epoch 38/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1369 - accuracy: 0.9627 - val_loss: 0.3054 - val_accuracy: 0.8516\n",
            "Epoch 39/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1345 - accuracy: 0.9601 - val_loss: 0.2986 - val_accuracy: 0.8828\n",
            "Epoch 40/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1358 - accuracy: 0.9601 - val_loss: 0.3004 - val_accuracy: 0.8646\n",
            "Epoch 41/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1237 - accuracy: 0.9757 - val_loss: 0.2991 - val_accuracy: 0.8698\n",
            "Epoch 42/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1198 - accuracy: 0.9714 - val_loss: 0.3059 - val_accuracy: 0.8516\n",
            "Epoch 43/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1198 - accuracy: 0.9688 - val_loss: 0.3141 - val_accuracy: 0.8385\n",
            "Epoch 44/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1216 - accuracy: 0.9653 - val_loss: 0.3037 - val_accuracy: 0.8542\n",
            "Epoch 45/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1138 - accuracy: 0.9774 - val_loss: 0.3010 - val_accuracy: 0.8828\n",
            "Epoch 46/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1113 - accuracy: 0.9800 - val_loss: 0.2997 - val_accuracy: 0.8776\n",
            "Epoch 47/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1068 - accuracy: 0.9748 - val_loss: 0.3022 - val_accuracy: 0.8828\n",
            "Epoch 48/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1101 - accuracy: 0.9688 - val_loss: 0.3013 - val_accuracy: 0.8594\n",
            "Epoch 49/100\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1062 - accuracy: 0.9783 - val_loss: 0.3017 - val_accuracy: 0.8620\n",
            "Epoch 00049: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lcY2r331R7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc08103d-321d-4b75-ae03-f5bfeb88389e"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  conv_base = make_conv_base(vgg19.VGG19)\n",
        "  for layer in conv_base.layers[:5]:\n",
        "    layer.trainable = False\n",
        "  model = make_model_logistic(conv_base)\n",
        "  time_callback = TimeHistory()\n",
        "  train_model(model, X_train, Y_train, [time_callback, checkpointer])\n",
        "  model.load_weights('weights.hdf5')\n",
        "  Y_pred, evaluation, prediction_time = evaluate_model(model, X_test, Y_test)\n",
        "  print('number positive predictions:', np.sum(1-np.argmax(Y_pred,axis=1)))\n",
        "  auc = roc_auc_score(Y_test, Y_pred)\n",
        "  fpr, tpr, thresholds = roc_curve(Y_test[:,0], Y_pred[:,0])\n",
        "  plt.plot(fpr, tpr)\n",
        "  plt.plot([i/100 for i in range(100)], [i/100 for i in range(100)], color='black')\n",
        "  plt.xlabel('FPR')\n",
        "  plt.ylabel('TPR')\n",
        "  plt.title('Receiver Operating Characteristic (ROC)')\n",
        "  plt.savefig('6.802/{}roc.png'.format('vgg19_frozen_roc'))\n",
        "  print('AUC ROC:', auc)\n",
        "  print('loss:', evaluation[0])\n",
        "  print('accuracy:', evaluation[1])\n",
        "  print('training time:', np.sum(time_callback.times))\n",
        "  print('prediction time:', prediction_time)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy\n",
            "\tvalidation       \t (min:    0.797, max:    0.872, cur:    0.852)\n",
            "\ttraining         \t (min:    0.656, max:    0.998, cur:    0.998)\n",
            "Loss\n",
            "\tvalidation       \t (min:    0.318, max:    0.587, cur:    0.563)\n",
            "\ttraining         \t (min:    0.008, max:    0.673, cur:    0.008)\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.31809\n",
            "Epoch 00016: early stopping\n",
            "385/385 [==============================] - 1s 3ms/step\n",
            "number positive predictions: 110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c1cbe9d69366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TPR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Receiver Operating Characteristic (ROC)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'6.802/{}roc.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC ROC:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x0HVKVG20dQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50c6fa20-b2c8-4ce1-c909-c2f33c94087b"
      },
      "source": [
        "plt.savefig('6.802/{}roc.png'.format('vgg19_frozen_roc.png'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytRyibHRYQsw",
        "colab_type": "text"
      },
      "source": [
        "## Training and Evaluation (multi-class classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqIsJ7l_poiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1d5b2901-d55f-4560-cd35-52ee4a37e810"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "raw_X = np.load('gdrive/My Drive/6.802/data.npy')\n",
        "raw_Y_multiclass = np.load('gdrive/My Drive/6.802/labels_multiclass.npy')\n",
        "\n",
        "print('Loaded pre-processed multi-class data from Google Drive.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Loaded pre-processed multi-class data from Google Drive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KY04Nizp81a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a96e610-d178-4f13-cc74-7f4bacaf0e8e"
      },
      "source": [
        "lb_multi = preprocessing.LabelBinarizer()\n",
        "lb_multi.fit([value for value in scoring_encoding.values()])\n",
        "binarized_labels_multiclass = lb_multi.transform(raw_Y_multiclass)\n",
        "\n",
        "X, Y_multiclass = shuffle(raw_X, binarized_labels_multiclass)\n",
        "X_positive = X[raw_Y_multiclass!=0]\n",
        "Y_positive = Y_multiclass[raw_Y_multiclass!=0]\n",
        "assert X_positive.shape[0] == Y_positive.shape[0]\n",
        "\n",
        "X_train, X_test, Y_multiclass_train, Y_multiclass_test = train_test_split(X, Y_multiclass, test_size = 0.2)\n",
        "X_positive_train, X_positive_test, Y_positive_train, Y_positive_test = train_test_split(X_positive, Y_positive, test_size = 0.2)\n",
        "\n",
        "print('Split data into train and test sets.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split data into train and test sets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uul5nIVIZBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b244cab-2258-4ce8-8cc3-c40d827cf672"
      },
      "source": [
        "def make_model_multiclass(conv_base, dropout_rate, learning_rate):\n",
        "  model = K.models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(K.layers.Flatten())\n",
        "  model.add(K.layers.Dense(1024, activation='relu'))\n",
        "  model.add(K.layers.Dropout(dropout_rate))\n",
        "  model.add(K.layers.Dense(len([score for score in scoring_encoding.values()]), activation='softmax'))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer=K.optimizers.Adam(learning_rate=learning_rate),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "dropout_rates = [0.1, 0.3, 0.5, 0.7]\n",
        "learning_rates = [10e-2, 10e-4, 10e-6, 10e-8]\n",
        "\n",
        "def make_model_positive(conv_base, dropout_rate, learning_rate):\n",
        "  model = K.models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(K.layers.Flatten())\n",
        "  model.add(K.layers.Dense(1024, activation='relu'))\n",
        "  model.add(K.layers.Dropout(dropout_rate))\n",
        "  model.add(K.layers.Dense(len([score for score in scoring_encoding.values()]-1), activation='softmax'))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer=K.optimizers.Adam(learning_rate=learning_rate),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def grid_search_multiclass(base, x_train, y_train):\n",
        "  result = {}\n",
        "  heatmap_accuracy = []\n",
        "  heatmap_loss = []\n",
        "  conv_base = make_conv_base(base)\n",
        "  for layer in conv_base.layers[:5]:\n",
        "    layer.trainable = False\n",
        "  for dropout_rate in dropout_rates:\n",
        "    for learning_rate in learning_rates:\n",
        "      heatmap_accuracy_internal = []\n",
        "      heatmap_loss_internal = []\n",
        "      model = make_model_multiclass(conv_base, dropout_rate, learning_rate)\n",
        "      time_callback = TimeHistory()\n",
        "      history = model.fit(x_train, y_train,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=EPOCHS,\n",
        "              callbacks=[es, time_callback],\n",
        "              verbose=1,\n",
        "              validation_split = 0.25)\n",
        "      best_accuracy = max(history.history['accuracy'])\n",
        "      best_validation_loss = min(history.history['val_loss'])\n",
        "      heatmap_accuracy_internal.append(best_accuracy)\n",
        "      heatmap_loss_internal.append(best_validation_loss)\n",
        "      result[(dropout_rate, learning_rate)] = (best_validation_loss, best_accuracy, np.sum(time_callback.times))\n",
        "      conv_base = make_conv_base(base)\n",
        "      for layer in conv_base.layers[:5]:\n",
        "        layer.trainable = False\n",
        "    heatmap_accuracy.append(heatmap_accuracy_internal)\n",
        "    heatmap_loss.append(heatmap_loss_internal)\n",
        "  return result, np.array(heatmap_accuracy), np.array(heatmap_loss)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  print('VGG19, multiclass classifier')\n",
        "  result_vgg19, heatmap_accuracy_vgg19, heatmap_loss_vgg19 = grid_search_multiclass(vgg19.VGG19, X_train, Y_multiclass_train)\n",
        "  # print('VGG19, positive classifier')\n",
        "  # result_vgg19, heatmap_accuracy_vgg19, heatmap_loss_vgg19 = grid_search_multiclass(vgg19.VGG19, X_positive_train, Y_positive_train)\n",
        "  # print('nasnetmobile, multiclass classifier')\n",
        "  # result_nasnetmobile = grid_search_multiclass(nasnet.NASNetMobile)\n",
        "  # print(max(result.keys(), key= lambda x: result[x][1]))\n",
        "  #get_results_for_model(vgg19_base, make_model_multiclass, 'vgg19_multiclass', multiclass=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG19, multiclass classifier\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 13s 11ms/step - loss: 43496480938401172315105656832.0000 - accuracy: 0.0859 - val_loss: 44562985956673717649593597952.0000 - val_accuracy: 0.0990\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45365372165803673912252301312.0000 - accuracy: 0.0903 - val_loss: 44411344078889583412389085184.0000 - val_accuracy: 0.0990\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45145821346227414531833856000.0000 - accuracy: 0.0903 - val_loss: 44422818248851335932847063040.0000 - val_accuracy: 0.0990\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45303650048811490103066099712.0000 - accuracy: 0.0903 - val_loss: 44422430227738663075696345088.0000 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45292185192405855598175846400.0000 - accuracy: 0.0903 - val_loss: 44570827446218522695470940160.0000 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45386165532488835302464421888.0000 - accuracy: 0.0903 - val_loss: 44570699942323485215050170368.0000 - val_accuracy: 0.0990\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45444199612434745642461429760.0000 - accuracy: 0.0903 - val_loss: 44570396923807495215420276736.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45483712439857993510207619072.0000 - accuracy: 0.0903 - val_loss: 44570207635617646054536642560.0000 - val_accuracy: 0.0990\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45507781685936941473248313344.0000 - accuracy: 0.0903 - val_loss: 44569747598416100639203393536.0000 - val_accuracy: 0.0990\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45443674380340365322061086720.0000 - accuracy: 0.0903 - val_loss: 44569605927421614549846982656.0000 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45431601125719526975274483712.0000 - accuracy: 0.0903 - val_loss: 44569740514866376334735572992.0000 - val_accuracy: 0.0990\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 45439481443610967972002136064.0000 - accuracy: 0.0903 - val_loss: 44596903566875842534004752384.0000 - val_accuracy: 0.0990\n",
            "Epoch 00012: early stopping\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 6377790786.1752 - accuracy: 0.0608 - val_loss: 242160304128.0000 - val_accuracy: 0.0651\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 169472378401234016.0000 - accuracy: 0.0582 - val_loss: 1554411290772198656.0000 - val_accuracy: 0.0651\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 1406818012761471320064.0000 - accuracy: 0.0590 - val_loss: 1639136641214726275072.0000 - val_accuracy: 0.0651\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 7358534372814635401216.0000 - accuracy: 0.0512 - val_loss: 2840867924020534181888.0000 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 11406032182485666758656.0000 - accuracy: 0.0573 - val_loss: 3128888976614565085184.0000 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 16378109660069133025280.0000 - accuracy: 0.0564 - val_loss: 3568134430771233423360.0000 - val_accuracy: 0.0729\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 19358283897288408432640.0000 - accuracy: 0.0599 - val_loss: 3229676721525349679104.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 21318127481830225477632.0000 - accuracy: 0.0564 - val_loss: 4008862882755197796352.0000 - val_accuracy: 0.0729\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 26686763638727276232704.0000 - accuracy: 0.0573 - val_loss: 4199148035960933449728.0000 - val_accuracy: 0.0651\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 30091379622828086132736.0000 - accuracy: 0.0564 - val_loss: 5560977641182646501376.0000 - val_accuracy: 0.0729\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 33314013777886145675264.0000 - accuracy: 0.0608 - val_loss: 6149514795886863974400.0000 - val_accuracy: 0.0729\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7580 - accuracy: 0.1042 - val_loss: 0.7230 - val_accuracy: 0.1146\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 8.1820 - accuracy: 0.1059 - val_loss: 9.3927 - val_accuracy: 0.0391\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 478.4798 - accuracy: 0.1137 - val_loss: 413.6804 - val_accuracy: 0.0443\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 18379.7340 - accuracy: 0.1024 - val_loss: 5754.5026 - val_accuracy: 0.0521\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 531267.6133 - accuracy: 0.0929 - val_loss: 203041.0208 - val_accuracy: 0.0781\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 12326538.9583 - accuracy: 0.1068 - val_loss: 3877035.3333 - val_accuracy: 0.0625\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 215976694.2222 - accuracy: 0.1076 - val_loss: 73665424.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 3275991082.6667 - accuracy: 0.1050 - val_loss: 1834883157.3333 - val_accuracy: 0.0651\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 43513434908.4444 - accuracy: 0.0955 - val_loss: 14969023146.6667 - val_accuracy: 0.0990\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 453102261134.2222 - accuracy: 0.1111 - val_loss: 149859358037.3333 - val_accuracy: 0.0729\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 4255577691477.3330 - accuracy: 0.1181 - val_loss: 881025351680.0000 - val_accuracy: 0.0365\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7712 - accuracy: 0.2361 - val_loss: 0.7620 - val_accuracy: 0.2266\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7677 - accuracy: 0.2370 - val_loss: 0.7525 - val_accuracy: 0.2005\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7496 - accuracy: 0.2292 - val_loss: 0.7439 - val_accuracy: 0.1771\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7381 - accuracy: 0.2040 - val_loss: 0.7362 - val_accuracy: 0.1667\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7359 - accuracy: 0.1875 - val_loss: 0.7294 - val_accuracy: 0.1536\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7259 - accuracy: 0.1623 - val_loss: 0.7232 - val_accuracy: 0.1484\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7236 - accuracy: 0.1623 - val_loss: 0.7173 - val_accuracy: 0.1380\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7095 - accuracy: 0.1701 - val_loss: 0.7116 - val_accuracy: 0.1354\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7064 - accuracy: 0.1528 - val_loss: 0.7067 - val_accuracy: 0.1276\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7008 - accuracy: 0.1372 - val_loss: 0.7021 - val_accuracy: 0.1172\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6992 - accuracy: 0.1328 - val_loss: 0.6980 - val_accuracy: 0.1120\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7027 - accuracy: 0.1458 - val_loss: 0.6945 - val_accuracy: 0.0990\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6871 - accuracy: 0.1380 - val_loss: 0.6906 - val_accuracy: 0.0938\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6931 - accuracy: 0.1207 - val_loss: 0.6874 - val_accuracy: 0.1016\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6912 - accuracy: 0.1337 - val_loss: 0.6842 - val_accuracy: 0.1042\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6828 - accuracy: 0.1285 - val_loss: 0.6814 - val_accuracy: 0.1068\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6767 - accuracy: 0.1311 - val_loss: 0.6785 - val_accuracy: 0.1016\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6781 - accuracy: 0.1276 - val_loss: 0.6757 - val_accuracy: 0.0964\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6718 - accuracy: 0.1111 - val_loss: 0.6731 - val_accuracy: 0.0964\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6797 - accuracy: 0.1172 - val_loss: 0.6708 - val_accuracy: 0.0938\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6716 - accuracy: 0.1181 - val_loss: 0.6683 - val_accuracy: 0.0964\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6650 - accuracy: 0.1389 - val_loss: 0.6660 - val_accuracy: 0.0964\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6642 - accuracy: 0.1146 - val_loss: 0.6636 - val_accuracy: 0.0990\n",
            "Epoch 24/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6583 - accuracy: 0.1155 - val_loss: 0.6613 - val_accuracy: 0.0964\n",
            "Epoch 25/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6588 - accuracy: 0.1250 - val_loss: 0.6596 - val_accuracy: 0.0990\n",
            "Epoch 26/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6524 - accuracy: 0.1215 - val_loss: 0.6573 - val_accuracy: 0.0911\n",
            "Epoch 27/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6566 - accuracy: 0.1146 - val_loss: 0.6553 - val_accuracy: 0.0885\n",
            "Epoch 28/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6498 - accuracy: 0.1233 - val_loss: 0.6531 - val_accuracy: 0.0938\n",
            "Epoch 29/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6546 - accuracy: 0.1163 - val_loss: 0.6514 - val_accuracy: 0.0911\n",
            "Epoch 30/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6486 - accuracy: 0.1120 - val_loss: 0.6499 - val_accuracy: 0.0911\n",
            "Epoch 31/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6425 - accuracy: 0.1233 - val_loss: 0.6488 - val_accuracy: 0.1094\n",
            "Epoch 32/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6519 - accuracy: 0.1120 - val_loss: 0.6487 - val_accuracy: 0.1068\n",
            "Epoch 33/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6530 - accuracy: 0.1215 - val_loss: 0.6490 - val_accuracy: 0.1094\n",
            "Epoch 34/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6478 - accuracy: 0.1285 - val_loss: 0.6500 - val_accuracy: 0.1016\n",
            "Epoch 35/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6553 - accuracy: 0.1128 - val_loss: 0.6516 - val_accuracy: 0.1068\n",
            "Epoch 36/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6448 - accuracy: 0.1276 - val_loss: 0.6526 - val_accuracy: 0.1016\n",
            "Epoch 37/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6539 - accuracy: 0.1146 - val_loss: 0.6550 - val_accuracy: 0.0911\n",
            "Epoch 38/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6508 - accuracy: 0.1128 - val_loss: 0.6569 - val_accuracy: 0.0833\n",
            "Epoch 39/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6466 - accuracy: 0.1224 - val_loss: 0.6580 - val_accuracy: 0.0781\n",
            "Epoch 40/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6531 - accuracy: 0.1094 - val_loss: 0.6626 - val_accuracy: 0.0755\n",
            "Epoch 41/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6473 - accuracy: 0.1085 - val_loss: 0.6655 - val_accuracy: 0.0807\n",
            "Epoch 42/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6556 - accuracy: 0.1189 - val_loss: 0.6698 - val_accuracy: 0.0729\n",
            "Epoch 00042: early stopping\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 73792086157726375663659646976.0000 - accuracy: 0.0451 - val_loss: 87395596877266770688003276800.0000 - val_accuracy: 0.0339\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 78637263815117979719730987008.0000 - accuracy: 0.0408 - val_loss: 87449034389325837250905243648.0000 - val_accuracy: 0.0339\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 78766584771836591960219451392.0000 - accuracy: 0.0408 - val_loss: 87583037834765918988161515520.0000 - val_accuracy: 0.0339\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 79582246340210989934003093504.0000 - accuracy: 0.0382 - val_loss: 87933464974932657538552823808.0000 - val_accuracy: 0.0339\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 79338119407219951649926676480.0000 - accuracy: 0.0434 - val_loss: 87933685352035197319391477760.0000 - val_accuracy: 0.0339\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 78627239542843315904076316672.0000 - accuracy: 0.0425 - val_loss: 87933585395277970714505773056.0000 - val_accuracy: 0.0339\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 78889175044548646515144392704.0000 - accuracy: 0.0469 - val_loss: 87933431918367277451036327936.0000 - val_accuracy: 0.0339\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 79257270131849981889045594112.0000 - accuracy: 0.0365 - val_loss: 87932946301680628219915534336.0000 - val_accuracy: 0.0339\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 79217736578484934410600710144.0000 - accuracy: 0.0434 - val_loss: 87930717344700713747374669824.0000 - val_accuracy: 0.0339\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 78839749445170464367203844096.0000 - accuracy: 0.0512 - val_loss: 87906881986939497963308711936.0000 - val_accuracy: 0.0339\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 79236556783041333835356700672.0000 - accuracy: 0.0391 - val_loss: 87906817447930910472948154368.0000 - val_accuracy: 0.0339\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 533775.3263 - accuracy: 0.0755 - val_loss: 29993867.6667 - val_accuracy: 0.0990\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 5012954656276041.0000 - accuracy: 0.0781 - val_loss: 22417228898325844.0000 - val_accuracy: 0.0156\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 634007054923311480832.0000 - accuracy: 0.0703 - val_loss: 1125725392357063393280.0000 - val_accuracy: 0.0651\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 5577242203586911272960.0000 - accuracy: 0.0703 - val_loss: 2856920207379862126592.0000 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 10072247211468527763456.0000 - accuracy: 0.0651 - val_loss: 5167888078407023460352.0000 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 14215457694032756473856.0000 - accuracy: 0.0720 - val_loss: 4383985710117395890176.0000 - val_accuracy: 0.0990\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 18542698142670274953216.0000 - accuracy: 0.0642 - val_loss: 5041525986237269147648.0000 - val_accuracy: 0.0651\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 22146626119929937526784.0000 - accuracy: 0.0634 - val_loss: 6359346134425341526016.0000 - val_accuracy: 0.1042\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 25844838519138471116800.0000 - accuracy: 0.0686 - val_loss: 7934642233684757839872.0000 - val_accuracy: 0.0990\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 27707522633769299214336.0000 - accuracy: 0.0590 - val_loss: 8580964324607827902464.0000 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 30336974921707439521792.0000 - accuracy: 0.0651 - val_loss: 10190505044833831223296.0000 - val_accuracy: 0.0990\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7499 - accuracy: 0.0799 - val_loss: 0.6405 - val_accuracy: 0.1016\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 4.9204 - accuracy: 0.1146 - val_loss: 3.0514 - val_accuracy: 0.0885\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 327.3084 - accuracy: 0.1033 - val_loss: 313.5128 - val_accuracy: 0.0651\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 17496.2751 - accuracy: 0.1137 - val_loss: 7752.9788 - val_accuracy: 0.0677\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 597200.0169 - accuracy: 0.1137 - val_loss: 667716.0625 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 15907136.4444 - accuracy: 0.1085 - val_loss: 7333341.3333 - val_accuracy: 0.0365\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 329759294.2222 - accuracy: 0.1068 - val_loss: 142697786.6667 - val_accuracy: 0.1068\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 5030695793.7778 - accuracy: 0.0972 - val_loss: 1353366741.3333 - val_accuracy: 0.0651\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 69951816248.8889 - accuracy: 0.1094 - val_loss: 26435771733.3333 - val_accuracy: 0.0651\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 784565420032.0000 - accuracy: 0.1050 - val_loss: 398715781120.0000 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 6040611309340.4443 - accuracy: 0.1146 - val_loss: 1483015367338.6667 - val_accuracy: 0.0990\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8338 - accuracy: 0.0252 - val_loss: 0.7438 - val_accuracy: 0.0286\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.8002 - accuracy: 0.0512 - val_loss: 0.7354 - val_accuracy: 0.0312\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7941 - accuracy: 0.0321 - val_loss: 0.7286 - val_accuracy: 0.0312\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7860 - accuracy: 0.0373 - val_loss: 0.7225 - val_accuracy: 0.0312\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7586 - accuracy: 0.0417 - val_loss: 0.7173 - val_accuracy: 0.0312\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7687 - accuracy: 0.0477 - val_loss: 0.7126 - val_accuracy: 0.0339\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7735 - accuracy: 0.0451 - val_loss: 0.7082 - val_accuracy: 0.0365\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7658 - accuracy: 0.0503 - val_loss: 0.7041 - val_accuracy: 0.0391\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7597 - accuracy: 0.0451 - val_loss: 0.7002 - val_accuracy: 0.0417\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7393 - accuracy: 0.0469 - val_loss: 0.6971 - val_accuracy: 0.0443\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7579 - accuracy: 0.0642 - val_loss: 0.6939 - val_accuracy: 0.0443\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7555 - accuracy: 0.0477 - val_loss: 0.6910 - val_accuracy: 0.0495\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7418 - accuracy: 0.0564 - val_loss: 0.6881 - val_accuracy: 0.0547\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7339 - accuracy: 0.0573 - val_loss: 0.6854 - val_accuracy: 0.0573\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7281 - accuracy: 0.0590 - val_loss: 0.6829 - val_accuracy: 0.0599\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7431 - accuracy: 0.0564 - val_loss: 0.6807 - val_accuracy: 0.0599\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7134 - accuracy: 0.0773 - val_loss: 0.6791 - val_accuracy: 0.0599\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7222 - accuracy: 0.0686 - val_loss: 0.6773 - val_accuracy: 0.0547\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7298 - accuracy: 0.0747 - val_loss: 0.6758 - val_accuracy: 0.0625\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7235 - accuracy: 0.0651 - val_loss: 0.6742 - val_accuracy: 0.0651\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7046 - accuracy: 0.0781 - val_loss: 0.6728 - val_accuracy: 0.0703\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7256 - accuracy: 0.0747 - val_loss: 0.6716 - val_accuracy: 0.0703\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7181 - accuracy: 0.0660 - val_loss: 0.6698 - val_accuracy: 0.0781\n",
            "Epoch 24/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7005 - accuracy: 0.0851 - val_loss: 0.6686 - val_accuracy: 0.0755\n",
            "Epoch 25/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7000 - accuracy: 0.0720 - val_loss: 0.6673 - val_accuracy: 0.0755\n",
            "Epoch 26/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7062 - accuracy: 0.0747 - val_loss: 0.6660 - val_accuracy: 0.0781\n",
            "Epoch 27/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7245 - accuracy: 0.0651 - val_loss: 0.6651 - val_accuracy: 0.0833\n",
            "Epoch 28/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7015 - accuracy: 0.0799 - val_loss: 0.6639 - val_accuracy: 0.0807\n",
            "Epoch 29/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6984 - accuracy: 0.0790 - val_loss: 0.6624 - val_accuracy: 0.0833\n",
            "Epoch 30/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6992 - accuracy: 0.0816 - val_loss: 0.6610 - val_accuracy: 0.0859\n",
            "Epoch 31/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7056 - accuracy: 0.0842 - val_loss: 0.6598 - val_accuracy: 0.0859\n",
            "Epoch 32/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7070 - accuracy: 0.0738 - val_loss: 0.6584 - val_accuracy: 0.0885\n",
            "Epoch 33/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6873 - accuracy: 0.0842 - val_loss: 0.6570 - val_accuracy: 0.0885\n",
            "Epoch 34/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7011 - accuracy: 0.0903 - val_loss: 0.6560 - val_accuracy: 0.0859\n",
            "Epoch 35/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6966 - accuracy: 0.0894 - val_loss: 0.6550 - val_accuracy: 0.0885\n",
            "Epoch 36/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6760 - accuracy: 0.0964 - val_loss: 0.6545 - val_accuracy: 0.0885\n",
            "Epoch 37/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7109 - accuracy: 0.0781 - val_loss: 0.6539 - val_accuracy: 0.0885\n",
            "Epoch 38/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6907 - accuracy: 0.0911 - val_loss: 0.6534 - val_accuracy: 0.0885\n",
            "Epoch 39/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7086 - accuracy: 0.0868 - val_loss: 0.6525 - val_accuracy: 0.0885\n",
            "Epoch 40/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7130 - accuracy: 0.0868 - val_loss: 0.6522 - val_accuracy: 0.0911\n",
            "Epoch 41/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6896 - accuracy: 0.0851 - val_loss: 0.6513 - val_accuracy: 0.0938\n",
            "Epoch 42/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.6869 - accuracy: 0.1024 - val_loss: 0.6508 - val_accuracy: 0.0938\n",
            "Epoch 43/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.6963 - accuracy: 0.0851 - val_loss: 0.6504 - val_accuracy: 0.0938\n",
            "Epoch 44/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7436 - accuracy: 0.0790 - val_loss: 0.6505 - val_accuracy: 0.0911\n",
            "Epoch 45/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7186 - accuracy: 0.0929 - val_loss: 0.6506 - val_accuracy: 0.0911\n",
            "Epoch 46/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7205 - accuracy: 0.0851 - val_loss: 0.6508 - val_accuracy: 0.0885\n",
            "Epoch 47/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7167 - accuracy: 0.0946 - val_loss: 0.6523 - val_accuracy: 0.0833\n",
            "Epoch 48/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7226 - accuracy: 0.0938 - val_loss: 0.6530 - val_accuracy: 0.0729\n",
            "Epoch 49/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7357 - accuracy: 0.1024 - val_loss: 0.6519 - val_accuracy: 0.0781\n",
            "Epoch 50/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7594 - accuracy: 0.0920 - val_loss: 0.6535 - val_accuracy: 0.0833\n",
            "Epoch 51/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7393 - accuracy: 0.1076 - val_loss: 0.6540 - val_accuracy: 0.0885\n",
            "Epoch 52/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.7858 - accuracy: 0.0998 - val_loss: 0.6546 - val_accuracy: 0.0885\n",
            "Epoch 53/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 0.8143 - accuracy: 0.0998 - val_loss: 0.6587 - val_accuracy: 0.0911\n",
            "Epoch 00053: early stopping\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 39164212360045007399355940864.0000 - accuracy: 0.0877 - val_loss: 44997209128895736619479334912.0000 - val_accuracy: 0.0990\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 41961422324167775203532734464.0000 - accuracy: 0.0903 - val_loss: 45057494072354972964034183168.0000 - val_accuracy: 0.0990\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 42336987145830219770287357952.0000 - accuracy: 0.0903 - val_loss: 45058530238267419679990480896.0000 - val_accuracy: 0.0990\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 42122572162157767780391190528.0000 - accuracy: 0.0903 - val_loss: 45058537321817143984458301440.0000 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 40942223087429994441175203840.0000 - accuracy: 0.0903 - val_loss: 45058497181702039592473985024.0000 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 41763297143677982054801211392.0000 - accuracy: 0.0903 - val_loss: 45058566049546584373497692160.0000 - val_accuracy: 0.0990\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 41396635425781062934131113984.0000 - accuracy: 0.0903 - val_loss: 45058207936754963826704646144.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 41356724476627937851330265088.0000 - accuracy: 0.0903 - val_loss: 45086681838993969523688734720.0000 - val_accuracy: 0.0990\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 41648583581494086880555171840.0000 - accuracy: 0.0903 - val_loss: 45096380005627619886378254336.0000 - val_accuracy: 0.0990\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 41651402243988549700042096640.0000 - accuracy: 0.0903 - val_loss: 45096341046104136211805241344.0000 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 41155020135874672682694868992.0000 - accuracy: 0.0903 - val_loss: 45096305628355514689466138624.0000 - val_accuracy: 0.0990\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1670607912492.5730 - accuracy: 0.0755 - val_loss: 31648617157973.3320 - val_accuracy: 0.0729\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 7ms/step - loss: 41843941177666740224.0000 - accuracy: 0.0738 - val_loss: 289750179764243890176.0000 - val_accuracy: 0.0990\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 11713411590596730028032.0000 - accuracy: 0.0677 - val_loss: 3376903990768710975488.0000 - val_accuracy: 0.0651\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 27480934089067319001088.0000 - accuracy: 0.0668 - val_loss: 6254832974372799512576.0000 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 40374300658715389329408.0000 - accuracy: 0.0556 - val_loss: 12269220453490148507648.0000 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 47837655702994614747136.0000 - accuracy: 0.0703 - val_loss: 14254827317550299217920.0000 - val_accuracy: 0.0990\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 62113435642511291842560.0000 - accuracy: 0.0712 - val_loss: 16817894545381165891584.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 70669715237161542877184.0000 - accuracy: 0.0564 - val_loss: 15673181601695138840576.0000 - val_accuracy: 0.0990\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 77914273151744133300224.0000 - accuracy: 0.0642 - val_loss: 25968169782583998021632.0000 - val_accuracy: 0.0990\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 82751231225132425936896.0000 - accuracy: 0.0720 - val_loss: 31360064654656617316352.0000 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 88029817782380221431808.0000 - accuracy: 0.0747 - val_loss: 29652349215553626308608.0000 - val_accuracy: 0.0990\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8124 - accuracy: 0.1285 - val_loss: 0.6734 - val_accuracy: 0.1042\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 9.1996 - accuracy: 0.1155 - val_loss: 11.3884 - val_accuracy: 0.0651\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 433.4040 - accuracy: 0.1181 - val_loss: 295.7853 - val_accuracy: 0.0964\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 17568.0442 - accuracy: 0.1163 - val_loss: 12159.6426 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 479535.8880 - accuracy: 0.1128 - val_loss: 282428.3958 - val_accuracy: 0.0469\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 14304938.3194 - accuracy: 0.1007 - val_loss: 5595263.0000 - val_accuracy: 0.1042\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 302391560.8889 - accuracy: 0.1250 - val_loss: 116496376.0000 - val_accuracy: 0.1016\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 4245210218.6667 - accuracy: 0.0990 - val_loss: 1669680341.3333 - val_accuracy: 0.0651\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 53313437923.5556 - accuracy: 0.1137 - val_loss: 41312764586.6667 - val_accuracy: 0.0651\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 686705589361.7777 - accuracy: 0.1120 - val_loss: 228664579413.3333 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 6154507365034.6670 - accuracy: 0.0920 - val_loss: 1450913955840.0000 - val_accuracy: 0.0755\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8176 - accuracy: 0.0460 - val_loss: 0.7456 - val_accuracy: 0.0260\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7878 - accuracy: 0.0651 - val_loss: 0.7399 - val_accuracy: 0.0339\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7863 - accuracy: 0.0564 - val_loss: 0.7351 - val_accuracy: 0.0365\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7816 - accuracy: 0.0729 - val_loss: 0.7308 - val_accuracy: 0.0417\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7644 - accuracy: 0.0703 - val_loss: 0.7271 - val_accuracy: 0.0417\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7992 - accuracy: 0.0642 - val_loss: 0.7234 - val_accuracy: 0.0469\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7826 - accuracy: 0.0660 - val_loss: 0.7197 - val_accuracy: 0.0495\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7602 - accuracy: 0.0747 - val_loss: 0.7171 - val_accuracy: 0.0495\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7669 - accuracy: 0.0686 - val_loss: 0.7147 - val_accuracy: 0.0495\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7536 - accuracy: 0.0764 - val_loss: 0.7125 - val_accuracy: 0.0495\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7654 - accuracy: 0.0703 - val_loss: 0.7108 - val_accuracy: 0.0521\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7686 - accuracy: 0.0773 - val_loss: 0.7094 - val_accuracy: 0.0547\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7815 - accuracy: 0.0625 - val_loss: 0.7079 - val_accuracy: 0.0547\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7611 - accuracy: 0.0694 - val_loss: 0.7062 - val_accuracy: 0.0521\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7428 - accuracy: 0.0755 - val_loss: 0.7048 - val_accuracy: 0.0521\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7407 - accuracy: 0.0825 - val_loss: 0.7033 - val_accuracy: 0.0573\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7487 - accuracy: 0.0842 - val_loss: 0.7016 - val_accuracy: 0.0521\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7479 - accuracy: 0.0877 - val_loss: 0.6998 - val_accuracy: 0.0521\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7639 - accuracy: 0.0703 - val_loss: 0.6981 - val_accuracy: 0.0521\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7564 - accuracy: 0.0790 - val_loss: 0.6965 - val_accuracy: 0.0521\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7470 - accuracy: 0.0885 - val_loss: 0.6952 - val_accuracy: 0.0495\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7469 - accuracy: 0.0885 - val_loss: 0.6938 - val_accuracy: 0.0521\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7604 - accuracy: 0.0842 - val_loss: 0.6927 - val_accuracy: 0.0573\n",
            "Epoch 24/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7373 - accuracy: 0.1024 - val_loss: 0.6918 - val_accuracy: 0.0625\n",
            "Epoch 25/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7391 - accuracy: 0.1016 - val_loss: 0.6919 - val_accuracy: 0.0625\n",
            "Epoch 26/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7696 - accuracy: 0.0807 - val_loss: 0.6912 - val_accuracy: 0.0677\n",
            "Epoch 27/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7574 - accuracy: 0.1094 - val_loss: 0.6913 - val_accuracy: 0.0651\n",
            "Epoch 28/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7610 - accuracy: 0.1137 - val_loss: 0.6916 - val_accuracy: 0.0677\n",
            "Epoch 29/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7636 - accuracy: 0.1042 - val_loss: 0.6917 - val_accuracy: 0.0703\n",
            "Epoch 30/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7579 - accuracy: 0.1137 - val_loss: 0.6922 - val_accuracy: 0.0729\n",
            "Epoch 31/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7605 - accuracy: 0.1207 - val_loss: 0.6916 - val_accuracy: 0.0781\n",
            "Epoch 32/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7704 - accuracy: 0.1050 - val_loss: 0.6907 - val_accuracy: 0.0859\n",
            "Epoch 33/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7537 - accuracy: 0.1241 - val_loss: 0.6899 - val_accuracy: 0.0859\n",
            "Epoch 34/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7724 - accuracy: 0.1215 - val_loss: 0.6881 - val_accuracy: 0.0833\n",
            "Epoch 35/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7756 - accuracy: 0.1137 - val_loss: 0.6870 - val_accuracy: 0.0859\n",
            "Epoch 36/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7829 - accuracy: 0.1241 - val_loss: 0.6862 - val_accuracy: 0.0833\n",
            "Epoch 37/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8128 - accuracy: 0.1163 - val_loss: 0.6854 - val_accuracy: 0.0833\n",
            "Epoch 38/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8064 - accuracy: 0.1311 - val_loss: 0.6835 - val_accuracy: 0.0859\n",
            "Epoch 39/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7915 - accuracy: 0.1267 - val_loss: 0.6818 - val_accuracy: 0.0911\n",
            "Epoch 40/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8043 - accuracy: 0.1354 - val_loss: 0.6791 - val_accuracy: 0.0938\n",
            "Epoch 41/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.7860 - accuracy: 0.1406 - val_loss: 0.6771 - val_accuracy: 0.0938\n",
            "Epoch 42/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8497 - accuracy: 0.1302 - val_loss: 0.6757 - val_accuracy: 0.1016\n",
            "Epoch 43/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8590 - accuracy: 0.1319 - val_loss: 0.6725 - val_accuracy: 0.0911\n",
            "Epoch 44/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8745 - accuracy: 0.1285 - val_loss: 0.6703 - val_accuracy: 0.0807\n",
            "Epoch 45/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9318 - accuracy: 0.1189 - val_loss: 0.6693 - val_accuracy: 0.0885\n",
            "Epoch 46/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9298 - accuracy: 0.1233 - val_loss: 0.6713 - val_accuracy: 0.0859\n",
            "Epoch 47/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9088 - accuracy: 0.1276 - val_loss: 0.6742 - val_accuracy: 0.0911\n",
            "Epoch 48/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0097 - accuracy: 0.1302 - val_loss: 0.6737 - val_accuracy: 0.0911\n",
            "Epoch 49/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0314 - accuracy: 0.1415 - val_loss: 0.6759 - val_accuracy: 0.0911\n",
            "Epoch 50/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0191 - accuracy: 0.1259 - val_loss: 0.6830 - val_accuracy: 0.0911\n",
            "Epoch 51/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.1068 - accuracy: 0.1328 - val_loss: 0.6935 - val_accuracy: 0.0859\n",
            "Epoch 52/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.2795 - accuracy: 0.1319 - val_loss: 0.6981 - val_accuracy: 0.0807\n",
            "Epoch 53/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.3151 - accuracy: 0.1094 - val_loss: 0.7026 - val_accuracy: 0.0729\n",
            "Epoch 54/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.4325 - accuracy: 0.1259 - val_loss: 0.7129 - val_accuracy: 0.0833\n",
            "Epoch 55/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.5809 - accuracy: 0.1276 - val_loss: 0.7223 - val_accuracy: 0.0807\n",
            "Epoch 00055: early stopping\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 6613833425965359620281073664.0000 - accuracy: 0.0920 - val_loss: 7114499769893972399525724160.0000 - val_accuracy: 0.0990\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7104072358375044419329982464.0000 - accuracy: 0.0903 - val_loss: 7126048956614958371997483008.0000 - val_accuracy: 0.0990\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7147153933899559799374217216.0000 - accuracy: 0.0903 - val_loss: 7124407343966350811580071936.0000 - val_accuracy: 0.0990\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7099937647768492831057903616.0000 - accuracy: 0.0903 - val_loss: 7124168667693695408424353792.0000 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7099896179487815131985870848.0000 - accuracy: 0.0911 - val_loss: 7123942781163598510232174592.0000 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7235679153633740920128012288.0000 - accuracy: 0.0894 - val_loss: 7123722945165557788772925440.0000 - val_accuracy: 0.0990\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7257560927410562473211723776.0000 - accuracy: 0.0903 - val_loss: 7123526032321485264042065920.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7237391700162226218504028160.0000 - accuracy: 0.0903 - val_loss: 7123681575267514782981292032.0000 - val_accuracy: 0.0990\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7135339769948146629926191104.0000 - accuracy: 0.0894 - val_loss: 7123474971733889236003192832.0000 - val_accuracy: 0.0990\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 7022371286150727046193479680.0000 - accuracy: 0.0903 - val_loss: 7123279878968565683785302016.0000 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 6983979955178734658300936192.0000 - accuracy: 0.0903 - val_loss: 7123046712123473995052875776.0000 - val_accuracy: 0.0990\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 393222028.1234 - accuracy: 0.0720 - val_loss: 6524394837.3333 - val_accuracy: 0.0990\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 232181542844597600.0000 - accuracy: 0.1033 - val_loss: 1388014453746477824.0000 - val_accuracy: 0.0990\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 4761467211472766500864.0000 - accuracy: 0.0686 - val_loss: 3094703512305583259648.0000 - val_accuracy: 0.0651\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 21643788400384920256512.0000 - accuracy: 0.0651 - val_loss: 4088925625130776788992.0000 - val_accuracy: 0.0990\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 32924178003291292041216.0000 - accuracy: 0.0712 - val_loss: 7332140354785986478080.0000 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 46030721335401042149376.0000 - accuracy: 0.0660 - val_loss: 10433851233549277986816.0000 - val_accuracy: 0.0651\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 50794906993410552365056.0000 - accuracy: 0.0712 - val_loss: 9621635485002310352896.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 66638079339940592746496.0000 - accuracy: 0.0720 - val_loss: 11651895164067871981568.0000 - val_accuracy: 0.0990\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 76960963692621320945664.0000 - accuracy: 0.0642 - val_loss: 13676392112110243414016.0000 - val_accuracy: 0.0651\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 95390008619795306512384.0000 - accuracy: 0.0547 - val_loss: 14517134598946896740352.0000 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 92172888997380958978048.0000 - accuracy: 0.0712 - val_loss: 14687257699570849677312.0000 - val_accuracy: 0.0990\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8811 - accuracy: 0.0972 - val_loss: 0.6537 - val_accuracy: 0.0833\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.5289 - accuracy: 0.1259 - val_loss: 0.9439 - val_accuracy: 0.0651\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 41.9036 - accuracy: 0.1094 - val_loss: 23.3174 - val_accuracy: 0.0677\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1995.6996 - accuracy: 0.1198 - val_loss: 958.6366 - val_accuracy: 0.0573\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 85940.5093 - accuracy: 0.1163 - val_loss: 50218.5540 - val_accuracy: 0.0990\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 2565844.6970 - accuracy: 0.0955 - val_loss: 1281308.0625 - val_accuracy: 0.0651\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 54553240.1667 - accuracy: 0.1068 - val_loss: 28003692.0000 - val_accuracy: 0.0990\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1061702068.4444 - accuracy: 0.1050 - val_loss: 515401776.0000 - val_accuracy: 0.1016\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 17602802801.7778 - accuracy: 0.0990 - val_loss: 5753922816.0000 - val_accuracy: 0.0859\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 200689866069.3333 - accuracy: 0.1068 - val_loss: 80202119850.6667 - val_accuracy: 0.0990\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 2143186317767.1111 - accuracy: 0.1016 - val_loss: 1065007666517.3334 - val_accuracy: 0.0651\n",
            "Epoch 00011: early stopping\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Model)                (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 45,723,720\n",
            "Trainable params: 45,611,144\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n",
            "Train on 1152 samples, validate on 384 samples\n",
            "Epoch 1/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0333 - accuracy: 0.1597 - val_loss: 0.7988 - val_accuracy: 0.0911\n",
            "Epoch 2/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0001 - accuracy: 0.1519 - val_loss: 0.7910 - val_accuracy: 0.0911\n",
            "Epoch 3/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9847 - accuracy: 0.1476 - val_loss: 0.7833 - val_accuracy: 0.0807\n",
            "Epoch 4/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0146 - accuracy: 0.1415 - val_loss: 0.7765 - val_accuracy: 0.0807\n",
            "Epoch 5/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9576 - accuracy: 0.1658 - val_loss: 0.7696 - val_accuracy: 0.0807\n",
            "Epoch 6/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9966 - accuracy: 0.1484 - val_loss: 0.7632 - val_accuracy: 0.0807\n",
            "Epoch 7/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9820 - accuracy: 0.1502 - val_loss: 0.7571 - val_accuracy: 0.0807\n",
            "Epoch 8/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9273 - accuracy: 0.1484 - val_loss: 0.7511 - val_accuracy: 0.0755\n",
            "Epoch 9/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9625 - accuracy: 0.1363 - val_loss: 0.7454 - val_accuracy: 0.0677\n",
            "Epoch 10/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9536 - accuracy: 0.1562 - val_loss: 0.7397 - val_accuracy: 0.0651\n",
            "Epoch 11/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9130 - accuracy: 0.1450 - val_loss: 0.7341 - val_accuracy: 0.0573\n",
            "Epoch 12/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9572 - accuracy: 0.1363 - val_loss: 0.7289 - val_accuracy: 0.0573\n",
            "Epoch 13/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9004 - accuracy: 0.1589 - val_loss: 0.7240 - val_accuracy: 0.0573\n",
            "Epoch 14/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9221 - accuracy: 0.1293 - val_loss: 0.7193 - val_accuracy: 0.0599\n",
            "Epoch 15/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9204 - accuracy: 0.1562 - val_loss: 0.7147 - val_accuracy: 0.0521\n",
            "Epoch 16/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9124 - accuracy: 0.1250 - val_loss: 0.7098 - val_accuracy: 0.0469\n",
            "Epoch 17/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9222 - accuracy: 0.1198 - val_loss: 0.7054 - val_accuracy: 0.0443\n",
            "Epoch 18/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9040 - accuracy: 0.1502 - val_loss: 0.7011 - val_accuracy: 0.0521\n",
            "Epoch 19/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8551 - accuracy: 0.1519 - val_loss: 0.6970 - val_accuracy: 0.0469\n",
            "Epoch 20/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8904 - accuracy: 0.1215 - val_loss: 0.6928 - val_accuracy: 0.0469\n",
            "Epoch 21/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8992 - accuracy: 0.1267 - val_loss: 0.6891 - val_accuracy: 0.0469\n",
            "Epoch 22/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8493 - accuracy: 0.1181 - val_loss: 0.6857 - val_accuracy: 0.0443\n",
            "Epoch 23/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8559 - accuracy: 0.1302 - val_loss: 0.6829 - val_accuracy: 0.0443\n",
            "Epoch 24/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8611 - accuracy: 0.1337 - val_loss: 0.6802 - val_accuracy: 0.0417\n",
            "Epoch 25/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8771 - accuracy: 0.1241 - val_loss: 0.6780 - val_accuracy: 0.0469\n",
            "Epoch 26/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9024 - accuracy: 0.1215 - val_loss: 0.6755 - val_accuracy: 0.0443\n",
            "Epoch 27/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8729 - accuracy: 0.1137 - val_loss: 0.6733 - val_accuracy: 0.0443\n",
            "Epoch 28/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8832 - accuracy: 0.1042 - val_loss: 0.6714 - val_accuracy: 0.0495\n",
            "Epoch 29/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8573 - accuracy: 0.1215 - val_loss: 0.6696 - val_accuracy: 0.0521\n",
            "Epoch 30/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8798 - accuracy: 0.0981 - val_loss: 0.6683 - val_accuracy: 0.0495\n",
            "Epoch 31/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8739 - accuracy: 0.1120 - val_loss: 0.6669 - val_accuracy: 0.0521\n",
            "Epoch 32/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8948 - accuracy: 0.1024 - val_loss: 0.6656 - val_accuracy: 0.0599\n",
            "Epoch 33/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8811 - accuracy: 0.1137 - val_loss: 0.6647 - val_accuracy: 0.0573\n",
            "Epoch 34/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8829 - accuracy: 0.0920 - val_loss: 0.6635 - val_accuracy: 0.0573\n",
            "Epoch 35/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8689 - accuracy: 0.1181 - val_loss: 0.6632 - val_accuracy: 0.0651\n",
            "Epoch 36/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8738 - accuracy: 0.1128 - val_loss: 0.6626 - val_accuracy: 0.0677\n",
            "Epoch 37/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8587 - accuracy: 0.1207 - val_loss: 0.6625 - val_accuracy: 0.0703\n",
            "Epoch 38/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8684 - accuracy: 0.0981 - val_loss: 0.6614 - val_accuracy: 0.0755\n",
            "Epoch 39/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8864 - accuracy: 0.0903 - val_loss: 0.6600 - val_accuracy: 0.0833\n",
            "Epoch 40/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8909 - accuracy: 0.0955 - val_loss: 0.6584 - val_accuracy: 0.0885\n",
            "Epoch 41/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8757 - accuracy: 0.1076 - val_loss: 0.6569 - val_accuracy: 0.0990\n",
            "Epoch 42/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8747 - accuracy: 0.1146 - val_loss: 0.6551 - val_accuracy: 0.0911\n",
            "Epoch 43/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8504 - accuracy: 0.1146 - val_loss: 0.6535 - val_accuracy: 0.0911\n",
            "Epoch 44/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8473 - accuracy: 0.1033 - val_loss: 0.6519 - val_accuracy: 0.0911\n",
            "Epoch 45/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8971 - accuracy: 0.1042 - val_loss: 0.6508 - val_accuracy: 0.0938\n",
            "Epoch 46/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.8892 - accuracy: 0.1155 - val_loss: 0.6493 - val_accuracy: 0.0911\n",
            "Epoch 47/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9066 - accuracy: 0.1207 - val_loss: 0.6482 - val_accuracy: 0.0911\n",
            "Epoch 48/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9395 - accuracy: 0.0929 - val_loss: 0.6470 - val_accuracy: 0.0885\n",
            "Epoch 49/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9348 - accuracy: 0.1068 - val_loss: 0.6454 - val_accuracy: 0.0833\n",
            "Epoch 50/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9849 - accuracy: 0.0990 - val_loss: 0.6438 - val_accuracy: 0.0885\n",
            "Epoch 51/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 0.9699 - accuracy: 0.1102 - val_loss: 0.6418 - val_accuracy: 0.0911\n",
            "Epoch 52/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0045 - accuracy: 0.1128 - val_loss: 0.6413 - val_accuracy: 0.0885\n",
            "Epoch 53/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0259 - accuracy: 0.1111 - val_loss: 0.6406 - val_accuracy: 0.0938\n",
            "Epoch 54/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0646 - accuracy: 0.1137 - val_loss: 0.6395 - val_accuracy: 0.1016\n",
            "Epoch 55/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.1098 - accuracy: 0.1033 - val_loss: 0.6385 - val_accuracy: 0.0990\n",
            "Epoch 56/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.1031 - accuracy: 0.1085 - val_loss: 0.6374 - val_accuracy: 0.1016\n",
            "Epoch 57/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.0626 - accuracy: 0.1432 - val_loss: 0.6356 - val_accuracy: 0.1042\n",
            "Epoch 58/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.1595 - accuracy: 0.1259 - val_loss: 0.6351 - val_accuracy: 0.1016\n",
            "Epoch 59/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.1964 - accuracy: 0.1076 - val_loss: 0.6333 - val_accuracy: 0.0964\n",
            "Epoch 60/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.2075 - accuracy: 0.1163 - val_loss: 0.6328 - val_accuracy: 0.1016\n",
            "Epoch 61/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.3761 - accuracy: 0.1102 - val_loss: 0.6304 - val_accuracy: 0.0964\n",
            "Epoch 62/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.3898 - accuracy: 0.1259 - val_loss: 0.6298 - val_accuracy: 0.0911\n",
            "Epoch 63/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.5440 - accuracy: 0.1120 - val_loss: 0.6296 - val_accuracy: 0.0990\n",
            "Epoch 64/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.5189 - accuracy: 0.1163 - val_loss: 0.6288 - val_accuracy: 0.0964\n",
            "Epoch 65/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.8020 - accuracy: 0.1059 - val_loss: 0.6282 - val_accuracy: 0.0885\n",
            "Epoch 66/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.6994 - accuracy: 0.1302 - val_loss: 0.6277 - val_accuracy: 0.0781\n",
            "Epoch 67/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.8304 - accuracy: 0.1250 - val_loss: 0.6346 - val_accuracy: 0.0755\n",
            "Epoch 68/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 1.8875 - accuracy: 0.1189 - val_loss: 0.6419 - val_accuracy: 0.0703\n",
            "Epoch 69/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 2.1832 - accuracy: 0.1128 - val_loss: 0.6351 - val_accuracy: 0.0755\n",
            "Epoch 70/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 2.3339 - accuracy: 0.1111 - val_loss: 0.6330 - val_accuracy: 0.0781\n",
            "Epoch 71/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 2.5022 - accuracy: 0.1094 - val_loss: 0.6410 - val_accuracy: 0.0755\n",
            "Epoch 72/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 2.5956 - accuracy: 0.1163 - val_loss: 0.6470 - val_accuracy: 0.0807\n",
            "Epoch 73/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 3.1243 - accuracy: 0.1250 - val_loss: 0.6617 - val_accuracy: 0.0729\n",
            "Epoch 74/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 3.0979 - accuracy: 0.1181 - val_loss: 0.6714 - val_accuracy: 0.0833\n",
            "Epoch 75/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 3.2486 - accuracy: 0.1198 - val_loss: 0.6675 - val_accuracy: 0.0938\n",
            "Epoch 76/100\n",
            "1152/1152 [==============================] - 9s 8ms/step - loss: 3.8962 - accuracy: 0.1155 - val_loss: 0.6817 - val_accuracy: 0.0885\n",
            "Epoch 00076: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0QA_Xs-RbyU",
        "colab_type": "text"
      },
      "source": [
        "https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwlFGsTX6y6c",
        "colab_type": "code",
        "outputId": "3a3b572a-d90b-4884-d5a6-d4a017e79470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# ig, axs = plt.subplots(2,2)\n",
        "# axs[0,0].imshow(X[0])\n",
        "# axs[0,1].imshow(X[1])\n",
        "# axs[1,0].imshow(X[2])\n",
        "# axs[1,1].imshow(X[3])\n",
        "# print(Y[:4])\n",
        "# plt.savefig('6.802/patch_examples.png')\n",
        "# patient_image = pydicom.dcmread('/inbreast/dicom/20586908_6c613a14b80a8591_MG_R_CC_ANON.dcm').pixel_array\n",
        "# plt.imshow(patient_image, cmap='bone')\n",
        "# plt.scatter([3259], [3044], color='red')\n",
        "# print(inbreast_rois['20586908'])\n",
        "# plt.savefig('6.802/inbreast_example.png')\n",
        "# print(X_test.shape)\n",
        "# print(to_freeze[np.argmin(losses)])\n",
        "# print(len(to_freeze))\n",
        "# os.chdir('../..')\n",
        "# !pwd\n",
        "\n",
        "#K.utils.plot_model(make_model_multiclass(vgg19.VGG19), to_file='model.png')\n",
        "heatmap_accuracy = []\n",
        "heatmap_loss = []\n",
        "for dropout_rate in dropout_rates:\n",
        "  heatmap_accuracy_internal = []\n",
        "  heatmap_loss_internal = []\n",
        "  for learning_rate in learning_rates:\n",
        "    heatmap_accuracy_internal.append(result_vgg19[(dropout_rate, learning_rate)][1])\n",
        "    heatmap_loss_internal.append(result_vgg19[(dropout_rate, learning_rate)][0])\n",
        "  heatmap_accuracy.append(heatmap_accuracy_internal)\n",
        "  heatmap_loss.append(heatmap_loss_internal)\n",
        "print(result_vgg19)\n",
        "\n",
        "# print(result_vgg19[max(result_vgg19.keys(), key= lambda x: result_vgg19[x][1])])\n",
        "\n",
        "def plot_heatmap(heatmap):\n",
        "  fig, ax = plt.subplots()\n",
        "  im = ax.imshow(heatmap)\n",
        "\n",
        "  # We want to show all ticks...\n",
        "  ax.set_xticks(np.arange(len(dropout_rates)))\n",
        "  ax.set_yticks(np.arange(len(learning_rates)))\n",
        "  # ... and label them with the respective list entries\n",
        "  ax.set_xticklabels(dropout_rates)\n",
        "  ax.set_yticklabels(learning_rates)\n",
        "\n",
        "  # Rotate the tick labels and set their alignment.\n",
        "  plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "          rotation_mode=\"anchor\")\n",
        "\n",
        "  # Loop over data dimensions and create text annotations.\n",
        "  for i in range(len(dropout_rates)):\n",
        "      for j in range(len(learning_rates)):\n",
        "          text = ax.text(j, i, \"{:.2e}\".format(heatmap[i, j]),\n",
        "                        ha=\"center\", va=\"center\", color=\"w\")\n",
        "  ax.set_xlabel('Dropout Rate')\n",
        "  ax.set_ylabel('Learning Rate')\n",
        "  ax.set_title(\"Validation loss\")\n",
        "  fig.tight_layout()\n",
        "  plt.savefig('gdrive/My Drive/6.802/validation_loss_heatmap.png')\n",
        "\n",
        "print(heatmap_loss)\n",
        "plot_heatmap(np.array(heatmap_loss))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{(0.1, 0.1): (4.441134407888958e+28, 0.090277776, 107.0249240398407), (0.1, 0.001): (242160304128.0, 0.060763888, 95.12509655952454), (0.1, 1e-05): (0.7229830970366796, 0.11805555, 95.1922664642334), (0.1, 1e-07): (0.6487157344818115, 0.23697917, 361.9383502006531), (0.3, 0.1): (8.739559687726677e+28, 0.051215276, 95.11941576004028), (0.3, 0.001): (29993867.666666668, 0.078125, 95.15478754043579), (0.3, 1e-05): (0.6405117710431417, 0.114583336, 95.34840941429138), (0.3, 1e-07): (0.6504479050636292, 0.10763889, 457.7428946495056), (0.5, 0.1): (4.499720912889574e+28, 0.090277776, 95.41676473617554), (0.5, 0.001): (31648617157973.332, 0.075520836, 95.65843629837036), (0.5, 1e-05): (0.6733646591504415, 0.12847222, 95.76030087471008), (0.5, 1e-07): (0.6692565679550171, 0.14149305, 477.3529326915741), (0.7, 0.1): (7.114499769893972e+27, 0.09201389, 95.73676061630249), (0.7, 0.001): (6524394837.333333, 0.10329861, 95.87122011184692), (0.7, 1e-05): (0.6536648472150167, 0.12586805, 95.89531683921814), (0.7, 1e-07): (0.627682218949, 0.1657986, 660.3402652740479)}\n",
            "[[4.441134407888958e+28, 242160304128.0, 0.7229830970366796, 0.6487157344818115], [8.739559687726677e+28, 29993867.666666668, 0.6405117710431417, 0.6504479050636292], [4.499720912889574e+28, 31648617157973.332, 0.6733646591504415, 0.6692565679550171], [7.114499769893972e+27, 6524394837.333333, 0.6536648472150167, 0.627682218949]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGTCVILrfnGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cfaad521-34ef-42f9-c940-ee714fb47e24"
      },
      "source": [
        "print(Y_multiclass!=0)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ...  True False False]\n",
            " [False False False ... False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}